{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use inceptionv4 and multiple input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cv/miniconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1203, 75, 75, 1) (1203, 75, 75, 1) (1203, 1) (1203, 2)\n",
      "(401, 75, 75, 1) (401, 75, 75, 1) (401, 1) (401, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cv/miniconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#Define data clean function\n",
    "# if you need to do zero center, you should use data_normal rather than data_clean.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def plt_images(X_images):\n",
    "    plt.imshow(X_images,cmap = plt.cm.gray)\n",
    "\n",
    "def data_normal(X_,y_,is_training):\n",
    "    '''Create 3-channel 'images'. Return rescale-normalised images.'''\n",
    "    images_1 = []\n",
    "    images_2 = []\n",
    "    avergae_bright=[]\n",
    "    index=1\n",
    "    for i, row in X_.iterrows():\n",
    "        # Formulate the bands as 75x75 arrays\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "#         avei=(np.sum(band_1)+np.sum(band_2))/(band_1.shape[0]+band_2.shape[0])\n",
    "        # Rescale\n",
    "        r = (band_1 - band_1.min()) / (band_1.max() - band_1.min())\n",
    "        g = (band_2 - band_2.min()) / (band_2.max() - band_2.min())\n",
    "        \n",
    "        images_1.append(r[:,:,np.newaxis])\n",
    "        images_2.append(g[:,:,np.newaxis])\n",
    "#         avergae_bright.append(avei)\n",
    "        \n",
    "    X_data_angle=np.reshape(np.sin(X_[\"inc_angle\"]),(X_[\"inc_angle\"].shape[0],1))\n",
    "    X_data_plus=np.concatenate([X_data_angle[:, np.newaxis]], \n",
    "                              axis=2)\n",
    "    X_data_plus=X_data_plus.reshape(X_data_plus.shape[0],X_data_plus.shape[2])\n",
    "    if is_training:\n",
    "        y_data = keras.utils.to_categorical(y_, num_classes)\n",
    "    else:\n",
    "        y_data = None\n",
    "\n",
    "    return (np.array(images_1),np.array(images_2),X_data_plus,y_data)\n",
    "\n",
    "\n",
    "# Define threadsafe_generator\n",
    "# If we want to use data augmentation in training process,we have to use @threadsafe_generator to make any generator thread safe.\n",
    "\n",
    "# Note: A non thread safe generator in a multithreaded envrionment just crashes, yieldsing a 'ValueError: generator already executing' error.You can try it yourself by removing the @threadsafe_generator decorator from count().\n",
    "\n",
    "# Also, since we have to use multiple generators to feed both the image data and the angle data, we have to define our own generator: generator_img_angle()\n",
    "import threading\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "class threadsafe_iter:\n",
    "    \"\"\"Takes an iterator/generator and makes it thread-safe by\n",
    "    serializing call to the `next` method of given iterator/generator.\n",
    "    \"\"\"\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "        self.lock = threading.Lock()\n",
    " \n",
    "    def __iter__(self):\n",
    "        return self\n",
    " \n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            return self.it.__next__()\n",
    " \n",
    "def threadsafe_generator(f):\n",
    "    \"\"\"A decorator that takes a generator function and makes it thread-safe.\n",
    "    \"\"\"\n",
    "    def g(*a, **kw):\n",
    "        return threadsafe_iter(f(*a, **kw))\n",
    "    return g\n",
    " \n",
    "@threadsafe_generator\n",
    "def generator_img_plus_new( generator, X1,X2,X_plus, y, batch_size = 32 ):\n",
    "    SEED=816\n",
    "    generator_seed = np.random.randint( SEED )\n",
    "    gen_X1 = generator.flow( X1, y, \n",
    "                             batch_size = batch_size, seed = generator_seed )\n",
    "    gen_X2 = generator.flow( X1, X2, \n",
    "                             batch_size = batch_size, seed = generator_seed )\n",
    "    gen_X3 = generator.flow( X1, X_plus, \n",
    "                             batch_size = batch_size, seed = generator_seed )\n",
    "\n",
    "    while True:\n",
    "        X1i = gen_X1.next()\n",
    "        X2i = gen_X2.next()\n",
    "        X3i = gen_X3.next()\n",
    "        yield [ X1i[0], X2i[1],X3i[1] ], X1i[1]\n",
    "    \n",
    "#load data\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import json\n",
    "import keras\n",
    "import math\n",
    "#Load the data.\n",
    "train = pd.read_json(\"../input/train.json\")\n",
    "\n",
    "#use mean of angle to replace \"na\"\n",
    "inc_angle = train.inc_angle.replace('na',0)\n",
    "idx=np.where(inc_angle==0)\n",
    "inc_angle = inc_angle.drop(idx[0])\n",
    "inc_mean=np.mean(inc_angle)\n",
    "train.inc_angle = train.inc_angle.replace('na',inc_mean)\n",
    "\n",
    "\n",
    "#Do Data Cleaning on training data and validation data\n",
    "num_classes=2\n",
    "\n",
    "\n",
    "y_train=train['is_iceberg']\n",
    "\n",
    "X_train_cv, X_valid, y_train_cv, y_valid = train_test_split(train,y_train, random_state=1, train_size=0.75)\n",
    "# X_train_cv,X_train_angle,y_train_cv=data_clean(X_train_cv,y_train_cv,is_training=True)\n",
    "# X_valid,X_valid_angle,y_valid=data_clean(X_valid,y_valid,is_training=True)\n",
    "\n",
    "X_train_1,X_train_2,X_train_plus,y_train_cv=data_normal(X_train_cv,y_train_cv,is_training=True)\n",
    "X_valid_1,X_valid_2,X_valid_plus,y_valid=data_normal(X_valid,y_valid,is_training=True)\n",
    "\n",
    "print(X_train_1.shape,X_train_2.shape,X_train_plus.shape,y_train_cv.shape)\n",
    "print(X_valid_1.shape,X_valid_2.shape,X_valid_plus.shape,y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train model\n",
    "\n",
    "If we use data augmentaion, use the model.fit_generator version, otherwise use model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "38/38 [==============================] - 6s 169ms/step - loss: 15.6699 - acc: 0.5936 - val_loss: 14.8000 - val_acc: 0.5312\n",
      "Epoch 2/200\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 14.0486 - acc: 0.6005 - val_loss: 13.3138 - val_acc: 0.5312\n",
      "Epoch 3/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 12.6322 - acc: 0.6353 - val_loss: 12.0117 - val_acc: 0.5312\n",
      "Epoch 4/200\n",
      "38/38 [==============================] - 4s 92ms/step - loss: 11.3939 - acc: 0.6285 - val_loss: 10.8691 - val_acc: 0.5312\n",
      "Epoch 5/200\n",
      "38/38 [==============================] - 4s 92ms/step - loss: 10.3356 - acc: 0.6115 - val_loss: 9.8673 - val_acc: 0.5312\n",
      "Epoch 6/200\n",
      "38/38 [==============================] - 4s 94ms/step - loss: 9.3703 - acc: 0.6216 - val_loss: 8.9860 - val_acc: 0.5312\n",
      "Epoch 7/200\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 8.5472 - acc: 0.6030 - val_loss: 8.2099 - val_acc: 0.5312\n",
      "Epoch 8/200\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 7.8028 - acc: 0.6350 - val_loss: 7.5257 - val_acc: 0.5312\n",
      "Epoch 9/200\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 7.1424 - acc: 0.6548 - val_loss: 6.9245 - val_acc: 0.5312\n",
      "Epoch 10/200\n",
      "38/38 [==============================] - 4s 92ms/step - loss: 6.6067 - acc: 0.6337 - val_loss: 6.3923 - val_acc: 0.5337\n",
      "Epoch 11/200\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 6.0842 - acc: 0.6485 - val_loss: 5.9155 - val_acc: 0.5362\n",
      "Epoch 12/200\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 5.6394 - acc: 0.6597 - val_loss: 5.4881 - val_acc: 0.5511\n",
      "Epoch 13/200\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 5.2405 - acc: 0.6693 - val_loss: 5.1038 - val_acc: 0.5960\n",
      "Epoch 14/200\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 4.8918 - acc: 0.6817 - val_loss: 4.7637 - val_acc: 0.6559\n",
      "Epoch 15/200\n",
      "38/38 [==============================] - 3s 88ms/step - loss: 4.5901 - acc: 0.6597 - val_loss: 4.4643 - val_acc: 0.6459\n",
      "Epoch 16/200\n",
      "38/38 [==============================] - 3s 92ms/step - loss: 4.3161 - acc: 0.6512 - val_loss: 4.2046 - val_acc: 0.7207\n",
      "Epoch 17/200\n",
      "38/38 [==============================] - 4s 92ms/step - loss: 4.0464 - acc: 0.6956 - val_loss: 3.9488 - val_acc: 0.7681\n",
      "Epoch 18/200\n",
      "38/38 [==============================] - 3s 92ms/step - loss: 3.7917 - acc: 0.7258 - val_loss: 3.7475 - val_acc: 0.7681\n",
      "Epoch 19/200\n",
      "38/38 [==============================] - 3s 92ms/step - loss: 3.5802 - acc: 0.7609 - val_loss: 3.6010 - val_acc: 0.7606\n",
      "Epoch 20/200\n",
      "38/38 [==============================] - 4s 93ms/step - loss: 3.4262 - acc: 0.7562 - val_loss: 3.3874 - val_acc: 0.8030\n",
      "Epoch 21/200\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 3.2430 - acc: 0.7757 - val_loss: 3.2481 - val_acc: 0.7681\n",
      "Epoch 22/200\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 3.0969 - acc: 0.7922 - val_loss: 3.1701 - val_acc: 0.6933\n",
      "Epoch 23/200\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 2.9622 - acc: 0.7968 - val_loss: 3.0066 - val_acc: 0.7232\n",
      "Epoch 24/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 2.8292 - acc: 0.8018 - val_loss: 2.9412 - val_acc: 0.6708\n",
      "Epoch 25/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 2.7267 - acc: 0.7976 - val_loss: 2.7786 - val_acc: 0.7232\n",
      "Epoch 26/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 2.6197 - acc: 0.8056 - val_loss: 2.7152 - val_acc: 0.6783\n",
      "Epoch 27/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 2.5360 - acc: 0.8012 - val_loss: 2.5572 - val_acc: 0.7830\n",
      "Epoch 28/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 2.4425 - acc: 0.7919 - val_loss: 2.4470 - val_acc: 0.7406\n",
      "Epoch 29/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 2.3446 - acc: 0.8075 - val_loss: 2.4197 - val_acc: 0.7431\n",
      "Epoch 30/200\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 2.2804 - acc: 0.8039 - val_loss: 2.2619 - val_acc: 0.8603\n",
      "Epoch 31/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 2.1865 - acc: 0.8144 - val_loss: 2.1809 - val_acc: 0.8554\n",
      "Epoch 32/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 2.1096 - acc: 0.8278 - val_loss: 2.1215 - val_acc: 0.8279\n",
      "Epoch 33/200\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 2.0359 - acc: 0.8251 - val_loss: 2.0278 - val_acc: 0.8628\n",
      "Epoch 34/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 1.9625 - acc: 0.8327 - val_loss: 2.0214 - val_acc: 0.7606\n",
      "Epoch 35/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 1.9250 - acc: 0.8273 - val_loss: 1.9390 - val_acc: 0.8429\n",
      "Epoch 36/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 1.8437 - acc: 0.8467 - val_loss: 1.8513 - val_acc: 0.8603\n",
      "Epoch 37/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 1.8175 - acc: 0.8294 - val_loss: 1.8305 - val_acc: 0.7656\n",
      "Epoch 38/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 1.7572 - acc: 0.8443 - val_loss: 2.1020 - val_acc: 0.6384\n",
      "Epoch 39/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 1.7085 - acc: 0.8415 - val_loss: 1.7268 - val_acc: 0.8628\n",
      "Epoch 40/200\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 1.6556 - acc: 0.8434 - val_loss: 1.7903 - val_acc: 0.7307\n",
      "Epoch 41/200\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 1.6022 - acc: 0.8577 - val_loss: 2.0951 - val_acc: 0.5985\n",
      "Epoch 42/200\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 1.5698 - acc: 0.8448 - val_loss: 1.6864 - val_acc: 0.7606\n",
      "Epoch 43/200\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 1.5309 - acc: 0.8495 - val_loss: 1.6347 - val_acc: 0.7955\n",
      "Epoch 44/200\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 1.4953 - acc: 0.8338 - val_loss: 1.5333 - val_acc: 0.8229\n",
      "Epoch 45/200\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 1.4507 - acc: 0.8558 - val_loss: 1.5717 - val_acc: 0.7905\n",
      "Epoch 46/200\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 1.4193 - acc: 0.8577 - val_loss: 1.4771 - val_acc: 0.8105\n",
      "Epoch 47/200\n",
      "38/38 [==============================] - 3s 92ms/step - loss: 1.3758 - acc: 0.8700 - val_loss: 1.4771 - val_acc: 0.8080\n",
      "Epoch 48/200\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 1.3760 - acc: 0.8418 - val_loss: 1.5449 - val_acc: 0.7257\n",
      "Epoch 49/200\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 1.3152 - acc: 0.8714 - val_loss: 1.4607 - val_acc: 0.7382\n",
      "Epoch 50/200\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 1.2889 - acc: 0.8610 - val_loss: 1.3416 - val_acc: 0.8329\n",
      "Epoch 51/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 1.2557 - acc: 0.8560 - val_loss: 1.2996 - val_acc: 0.8603\n",
      "Epoch 52/200\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 1.2335 - acc: 0.8585 - val_loss: 1.3898 - val_acc: 0.7756\n",
      "Epoch 53/200\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 1.2000 - acc: 0.8744 - val_loss: 1.3540 - val_acc: 0.7506\n",
      "Epoch 54/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 1.1768 - acc: 0.8645 - val_loss: 1.2715 - val_acc: 0.8030\n",
      "Epoch 55/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 1.1608 - acc: 0.8684 - val_loss: 1.3074 - val_acc: 0.7481\n",
      "Epoch 56/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 1.1146 - acc: 0.8865 - val_loss: 1.2639 - val_acc: 0.7756\n",
      "Epoch 57/200\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 1.1005 - acc: 0.8684 - val_loss: 1.2402 - val_acc: 0.7805\n",
      "Epoch 58/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 1.0721 - acc: 0.8796 - val_loss: 1.1526 - val_acc: 0.8479\n",
      "Epoch 59/200\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 1.0547 - acc: 0.8758 - val_loss: 1.1420 - val_acc: 0.8105\n",
      "Epoch 60/200\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 1.0312 - acc: 0.8889 - val_loss: 1.0835 - val_acc: 0.8728\n",
      "Epoch 61/200\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 1.0296 - acc: 0.8857 - val_loss: 1.0676 - val_acc: 0.8778\n",
      "Epoch 62/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.9925 - acc: 0.8985 - val_loss: 1.0946 - val_acc: 0.8379\n",
      "Epoch 63/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.9720 - acc: 0.8950 - val_loss: 1.0377 - val_acc: 0.8603\n",
      "Epoch 64/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.9628 - acc: 0.8876 - val_loss: 1.0392 - val_acc: 0.8279\n",
      "Epoch 65/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.9628 - acc: 0.8799 - val_loss: 1.0505 - val_acc: 0.8703\n",
      "Epoch 66/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.9726 - acc: 0.8719 - val_loss: 1.0945 - val_acc: 0.8005\n",
      "Epoch 67/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.9285 - acc: 0.8958 - val_loss: 1.0771 - val_acc: 0.7830\n",
      "Epoch 68/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.8952 - acc: 0.8928 - val_loss: 1.0549 - val_acc: 0.7905\n",
      "Epoch 69/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.8763 - acc: 0.9027 - val_loss: 0.9810 - val_acc: 0.8329\n",
      "Epoch 70/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.8701 - acc: 0.8983 - val_loss: 0.9662 - val_acc: 0.8603\n",
      "Epoch 71/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.8563 - acc: 0.9029 - val_loss: 0.9860 - val_acc: 0.8254\n",
      "Epoch 72/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.8351 - acc: 0.8991 - val_loss: 0.9809 - val_acc: 0.8030\n",
      "Epoch 73/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.8423 - acc: 0.8969 - val_loss: 0.9886 - val_acc: 0.8055\n",
      "Epoch 74/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.8037 - acc: 0.9027 - val_loss: 0.9137 - val_acc: 0.8554\n",
      "Epoch 75/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.7851 - acc: 0.9219 - val_loss: 0.9405 - val_acc: 0.7905\n",
      "Epoch 76/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.7723 - acc: 0.9273 - val_loss: 1.2250 - val_acc: 0.6958\n",
      "Epoch 77/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.7878 - acc: 0.8895 - val_loss: 0.9139 - val_acc: 0.8155\n",
      "Epoch 78/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.7456 - acc: 0.9309 - val_loss: 0.8813 - val_acc: 0.8454\n",
      "Epoch 79/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.7514 - acc: 0.9073 - val_loss: 0.9661 - val_acc: 0.7756\n",
      "Epoch 80/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.7475 - acc: 0.9098 - val_loss: 1.1941 - val_acc: 0.7157\n",
      "Epoch 81/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.7311 - acc: 0.9180 - val_loss: 0.8699 - val_acc: 0.8504\n",
      "Epoch 82/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.7290 - acc: 0.9161 - val_loss: 0.8403 - val_acc: 0.8329\n",
      "Epoch 83/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.7161 - acc: 0.9183 - val_loss: 0.8656 - val_acc: 0.8304\n",
      "Epoch 84/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.6950 - acc: 0.9230 - val_loss: 0.8431 - val_acc: 0.8229\n",
      "Epoch 85/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.6761 - acc: 0.9356 - val_loss: 0.8235 - val_acc: 0.8329\n",
      "Epoch 86/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.6585 - acc: 0.9350 - val_loss: 0.8187 - val_acc: 0.8603\n",
      "Epoch 87/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.6487 - acc: 0.9416 - val_loss: 0.8616 - val_acc: 0.8005\n",
      "Epoch 88/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.6551 - acc: 0.9205 - val_loss: 0.8292 - val_acc: 0.8204\n",
      "Epoch 89/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.6555 - acc: 0.9315 - val_loss: 0.8724 - val_acc: 0.7980\n",
      "Epoch 90/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.6550 - acc: 0.9175 - val_loss: 0.8664 - val_acc: 0.7955\n",
      "Epoch 91/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.6458 - acc: 0.9216 - val_loss: 0.8713 - val_acc: 0.7805\n",
      "Epoch 92/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.6153 - acc: 0.9419 - val_loss: 0.7759 - val_acc: 0.8304\n",
      "Epoch 93/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.6624 - acc: 0.9081 - val_loss: 0.7792 - val_acc: 0.8429\n",
      "Epoch 94/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.6185 - acc: 0.9356 - val_loss: 0.7846 - val_acc: 0.8404\n",
      "Epoch 95/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.6012 - acc: 0.9482 - val_loss: 0.8155 - val_acc: 0.8055\n",
      "Epoch 96/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.5841 - acc: 0.9457 - val_loss: 0.8870 - val_acc: 0.7631\n",
      "Epoch 97/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.5840 - acc: 0.9471 - val_loss: 0.7399 - val_acc: 0.8554\n",
      "Epoch 98/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.5769 - acc: 0.9402 - val_loss: 0.7680 - val_acc: 0.8454\n",
      "Epoch 99/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.5716 - acc: 0.9465 - val_loss: 1.0091 - val_acc: 0.7182\n",
      "Epoch 100/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.5822 - acc: 0.9353 - val_loss: 0.8990 - val_acc: 0.7880\n",
      "Epoch 101/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.5629 - acc: 0.9410 - val_loss: 0.9273 - val_acc: 0.7406\n",
      "Epoch 102/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.5644 - acc: 0.9482 - val_loss: 0.8361 - val_acc: 0.7905\n",
      "Epoch 103/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.5488 - acc: 0.9468 - val_loss: 0.7707 - val_acc: 0.8229\n",
      "Epoch 104/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.5514 - acc: 0.9471 - val_loss: 0.8626 - val_acc: 0.7332\n",
      "Epoch 105/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.5478 - acc: 0.9441 - val_loss: 0.7346 - val_acc: 0.8279\n",
      "Epoch 106/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.5376 - acc: 0.9487 - val_loss: 0.7186 - val_acc: 0.8579\n",
      "Epoch 107/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.5338 - acc: 0.9498 - val_loss: 0.7140 - val_acc: 0.8329\n",
      "Epoch 108/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.5220 - acc: 0.9528 - val_loss: 0.7261 - val_acc: 0.8379\n",
      "Epoch 109/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.5301 - acc: 0.9408 - val_loss: 0.7916 - val_acc: 0.7955\n",
      "Epoch 110/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.5436 - acc: 0.9380 - val_loss: 0.8806 - val_acc: 0.7157\n",
      "Epoch 111/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.5131 - acc: 0.9534 - val_loss: 0.8586 - val_acc: 0.7506\n",
      "Epoch 112/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.5063 - acc: 0.9463 - val_loss: 0.7319 - val_acc: 0.8180\n",
      "Epoch 113/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.4900 - acc: 0.9630 - val_loss: 0.7095 - val_acc: 0.8329\n",
      "Epoch 114/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.4858 - acc: 0.9608 - val_loss: 0.7253 - val_acc: 0.8229\n",
      "Epoch 115/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.4676 - acc: 0.9718 - val_loss: 0.7603 - val_acc: 0.7980\n",
      "Epoch 116/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.4789 - acc: 0.9580 - val_loss: 0.7088 - val_acc: 0.8304\n",
      "Epoch 117/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.4850 - acc: 0.9498 - val_loss: 0.7034 - val_acc: 0.8504\n",
      "Epoch 118/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.4677 - acc: 0.9624 - val_loss: 0.7624 - val_acc: 0.8080\n",
      "Epoch 119/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.4564 - acc: 0.9663 - val_loss: 0.7433 - val_acc: 0.7855\n",
      "Epoch 120/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.4614 - acc: 0.9613 - val_loss: 0.8002 - val_acc: 0.7631\n",
      "Epoch 121/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.4658 - acc: 0.9627 - val_loss: 0.6791 - val_acc: 0.8329\n",
      "Epoch 122/200\n",
      "38/38 [==============================] - 3s 88ms/step - loss: 0.4576 - acc: 0.9559 - val_loss: 0.6824 - val_acc: 0.8329\n",
      "Epoch 123/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 3s 89ms/step - loss: 0.4505 - acc: 0.9641 - val_loss: 0.9171 - val_acc: 0.7456\n",
      "Epoch 124/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.4785 - acc: 0.9465 - val_loss: 0.7085 - val_acc: 0.8130\n",
      "Epoch 125/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.4465 - acc: 0.9641 - val_loss: 0.7300 - val_acc: 0.7905\n",
      "Epoch 126/200\n",
      "38/38 [==============================] - 3s 88ms/step - loss: 0.4402 - acc: 0.9638 - val_loss: 0.6425 - val_acc: 0.8678\n",
      "Epoch 127/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.4373 - acc: 0.9589 - val_loss: 0.6442 - val_acc: 0.8579\n",
      "Epoch 128/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.4255 - acc: 0.9704 - val_loss: 0.6836 - val_acc: 0.8155\n",
      "Epoch 129/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.4197 - acc: 0.9723 - val_loss: 0.7396 - val_acc: 0.7880\n",
      "Epoch 130/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.4114 - acc: 0.9753 - val_loss: 0.8271 - val_acc: 0.7332\n",
      "Epoch 131/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.4202 - acc: 0.9671 - val_loss: 0.7836 - val_acc: 0.7531\n",
      "Epoch 132/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3983 - acc: 0.9789 - val_loss: 0.6535 - val_acc: 0.8229\n",
      "Epoch 133/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.4191 - acc: 0.9605 - val_loss: 0.6616 - val_acc: 0.8354\n",
      "Epoch 134/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.4184 - acc: 0.9638 - val_loss: 0.8939 - val_acc: 0.7282\n",
      "Epoch 135/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3998 - acc: 0.9696 - val_loss: 0.6539 - val_acc: 0.8304\n",
      "Epoch 136/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.4065 - acc: 0.9655 - val_loss: 0.6306 - val_acc: 0.8429\n",
      "Epoch 137/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.4025 - acc: 0.9690 - val_loss: 0.9041 - val_acc: 0.7182\n",
      "Epoch 138/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3786 - acc: 0.9835 - val_loss: 0.6388 - val_acc: 0.8329\n",
      "Epoch 139/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3884 - acc: 0.9740 - val_loss: 0.8451 - val_acc: 0.7107\n",
      "Epoch 140/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3881 - acc: 0.9712 - val_loss: 0.9245 - val_acc: 0.7182\n",
      "Epoch 141/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3693 - acc: 0.9811 - val_loss: 0.6797 - val_acc: 0.8204\n",
      "Epoch 142/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.4022 - acc: 0.9578 - val_loss: 0.6605 - val_acc: 0.8254\n",
      "Epoch 143/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3928 - acc: 0.9655 - val_loss: 0.6322 - val_acc: 0.8504\n",
      "Epoch 144/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3704 - acc: 0.9753 - val_loss: 0.6267 - val_acc: 0.8354\n",
      "Epoch 145/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3723 - acc: 0.9698 - val_loss: 0.6364 - val_acc: 0.8429\n",
      "Epoch 146/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3791 - acc: 0.9756 - val_loss: 0.6531 - val_acc: 0.8254\n",
      "Epoch 147/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3693 - acc: 0.9778 - val_loss: 0.7583 - val_acc: 0.7431\n",
      "Epoch 148/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3790 - acc: 0.9690 - val_loss: 0.8286 - val_acc: 0.7282\n",
      "Epoch 149/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3783 - acc: 0.9674 - val_loss: 0.6862 - val_acc: 0.8155\n",
      "Epoch 150/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3690 - acc: 0.9704 - val_loss: 0.6700 - val_acc: 0.8130\n",
      "Epoch 151/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3776 - acc: 0.9696 - val_loss: 0.8425 - val_acc: 0.7855\n",
      "Epoch 152/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3528 - acc: 0.9786 - val_loss: 0.6159 - val_acc: 0.8379\n",
      "Epoch 153/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3418 - acc: 0.9860 - val_loss: 0.7143 - val_acc: 0.7980\n",
      "Epoch 154/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3764 - acc: 0.9687 - val_loss: 0.6589 - val_acc: 0.8180\n",
      "Epoch 155/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3421 - acc: 0.9827 - val_loss: 0.6424 - val_acc: 0.8155\n",
      "Epoch 156/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3563 - acc: 0.9756 - val_loss: 0.6521 - val_acc: 0.8354\n",
      "Epoch 157/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3630 - acc: 0.9638 - val_loss: 0.6551 - val_acc: 0.8080\n",
      "Epoch 158/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3540 - acc: 0.9709 - val_loss: 0.6359 - val_acc: 0.8204\n",
      "Epoch 159/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3516 - acc: 0.9737 - val_loss: 0.6134 - val_acc: 0.8279\n",
      "Epoch 160/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3429 - acc: 0.9745 - val_loss: 0.8760 - val_acc: 0.7581\n",
      "Epoch 161/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3744 - acc: 0.9646 - val_loss: 0.9260 - val_acc: 0.6983\n",
      "Epoch 162/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3600 - acc: 0.9715 - val_loss: 0.6988 - val_acc: 0.8005\n",
      "Epoch 163/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3628 - acc: 0.9712 - val_loss: 0.6117 - val_acc: 0.8279\n",
      "Epoch 164/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3465 - acc: 0.9753 - val_loss: 0.6634 - val_acc: 0.8155\n",
      "Epoch 165/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3531 - acc: 0.9649 - val_loss: 0.6725 - val_acc: 0.8080\n",
      "Epoch 166/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3419 - acc: 0.9789 - val_loss: 0.6489 - val_acc: 0.8005\n",
      "Epoch 167/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3456 - acc: 0.9778 - val_loss: 0.9133 - val_acc: 0.7057\n",
      "Epoch 168/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3183 - acc: 0.9860 - val_loss: 0.6468 - val_acc: 0.8080\n",
      "Epoch 169/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3479 - acc: 0.9707 - val_loss: 0.5998 - val_acc: 0.8354\n",
      "Epoch 170/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3300 - acc: 0.9811 - val_loss: 1.0106 - val_acc: 0.7431\n",
      "Epoch 171/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3477 - acc: 0.9696 - val_loss: 0.8638 - val_acc: 0.7132\n",
      "Epoch 172/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3154 - acc: 0.9833 - val_loss: 0.6800 - val_acc: 0.7830\n",
      "Epoch 173/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3290 - acc: 0.9712 - val_loss: 0.6474 - val_acc: 0.8204\n",
      "Epoch 174/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3303 - acc: 0.9811 - val_loss: 0.6055 - val_acc: 0.8080\n",
      "Epoch 175/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3156 - acc: 0.9811 - val_loss: 0.5930 - val_acc: 0.8429\n",
      "Epoch 176/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3280 - acc: 0.9770 - val_loss: 0.7087 - val_acc: 0.7706\n",
      "Epoch 177/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3138 - acc: 0.9803 - val_loss: 0.7011 - val_acc: 0.7880\n",
      "Epoch 178/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3170 - acc: 0.9778 - val_loss: 0.5882 - val_acc: 0.8279\n",
      "Epoch 179/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3508 - acc: 0.9671 - val_loss: 0.7330 - val_acc: 0.7531\n",
      "Epoch 180/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3256 - acc: 0.9737 - val_loss: 0.6720 - val_acc: 0.7880\n",
      "Epoch 181/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3389 - acc: 0.9679 - val_loss: 0.9360 - val_acc: 0.7007\n",
      "Epoch 182/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3179 - acc: 0.9822 - val_loss: 0.6021 - val_acc: 0.8354\n",
      "Epoch 183/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3168 - acc: 0.9759 - val_loss: 0.6102 - val_acc: 0.8279\n",
      "Epoch 184/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3033 - acc: 0.9811 - val_loss: 0.6666 - val_acc: 0.8130\n",
      "Epoch 185/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3112 - acc: 0.9778 - val_loss: 0.6927 - val_acc: 0.8055\n",
      "Epoch 186/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3205 - acc: 0.9731 - val_loss: 0.7953 - val_acc: 0.7207\n",
      "Epoch 187/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3083 - acc: 0.9803 - val_loss: 0.6806 - val_acc: 0.7830\n",
      "Epoch 188/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.2999 - acc: 0.9835 - val_loss: 0.6261 - val_acc: 0.8204\n",
      "Epoch 189/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3133 - acc: 0.9748 - val_loss: 0.6647 - val_acc: 0.7781\n",
      "Epoch 190/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3083 - acc: 0.9805 - val_loss: 0.6414 - val_acc: 0.8130\n",
      "Epoch 191/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.2969 - acc: 0.9816 - val_loss: 0.6113 - val_acc: 0.7955\n",
      "Epoch 192/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.2998 - acc: 0.9835 - val_loss: 0.7785 - val_acc: 0.7581\n",
      "Epoch 193/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3030 - acc: 0.9786 - val_loss: 0.6016 - val_acc: 0.8080\n",
      "Epoch 194/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.2924 - acc: 0.9830 - val_loss: 0.5790 - val_acc: 0.8329\n",
      "Epoch 195/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.2989 - acc: 0.9786 - val_loss: 0.6331 - val_acc: 0.8155\n",
      "Epoch 196/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3052 - acc: 0.9770 - val_loss: 0.6124 - val_acc: 0.8080\n",
      "Epoch 197/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3040 - acc: 0.9811 - val_loss: 1.1557 - val_acc: 0.6683\n",
      "Epoch 198/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.3061 - acc: 0.9772 - val_loss: 0.5828 - val_acc: 0.8404\n",
      "Epoch 199/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.2847 - acc: 0.9835 - val_loss: 0.6444 - val_acc: 0.8304\n",
      "Epoch 200/200\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.2940 - acc: 0.9835 - val_loss: 0.6221 - val_acc: 0.8204\n",
      "Saved trained model at /home/cv/wjb/Iceberg Classifier Challenge/iceberg_code/saved_models/keras_iceberg_myownmodel2.h5 \n",
      "401/401 [==============================] - 0s 920us/step\n",
      "Test loss: 0.622106108136\n",
      "Test accuracy: 0.820448878846\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import GlobalMaxPooling2D\n",
    "import os\n",
    "from keras import regularizers\n",
    "import math\n",
    "from keras.layers import advanced_activations\n",
    "\n",
    "#Macro defined\n",
    "batch_size =32\n",
    "num_classes =2\n",
    "epochs = 200\n",
    "batch_num_per_epoch=math.ceil(X_train_cv.shape[0]/batch_size)\n",
    "batch_num_val=math.ceil(X_valid.shape[0]/batch_size)\n",
    "data_augmentation = True\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_iceberg_myownmodel2.h5'\n",
    "filepath=\"keras_iceberg_epoch_mymodel.h5\"\n",
    "\n",
    "# create the base model\n",
    "def conv2d_block(inputs,kernel_size,filters):\n",
    "    x=Conv2D(filters=filters,kernel_size= kernel_size,strides=(1, 1), padding='same',\n",
    "           input_shape=X_train_cv.shape[1:],kernel_initializer='glorot_normal',\n",
    "           use_bias=True,kernel_regularizer=regularizers.l2(0.05))(inputs)\n",
    "    \n",
    "    x=BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, \n",
    "                                scale=True, beta_initializer='zeros', gamma_initializer='ones', \n",
    "                                moving_mean_initializer='zeros', moving_variance_initializer='ones')(x)\n",
    "#     x=advanced_activations.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=None)(x)\n",
    "    x=keras.layers.advanced_activations.LeakyReLU(alpha=0.3)(x)\n",
    "    x=MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x=Dropout(0.3)(x)\n",
    "    return x\n",
    "\n",
    "def dense_block(x,filters):\n",
    "    x=Dense(filters,kernel_initializer='glorot_normal',kernel_regularizer=regularizers.l2(0.05))(x)\n",
    "    x=keras.layers.advanced_activations.LeakyReLU(alpha=0.3)(x)\n",
    "    x=Dropout(0.1)(x)\n",
    "    return x\n",
    "\n",
    "def model_i(input_x,angle_input):\n",
    "    x= conv2d_block(input_x,(5,5),64)\n",
    "    x= conv2d_block(x,(3,3),128)\n",
    "    x= conv2d_block(x,(3,3),64)\n",
    "    image_out=GlobalMaxPooling2D()(x)\n",
    "    x = keras.layers.concatenate([image_out, angle_input],axis=-1)\n",
    "#     x=dense_block(x,64)\n",
    "    x=dense_block(x,16)\n",
    "    prediction = Dense(num_classes, activation='relu',kernel_initializer='glorot_normal',\n",
    "                   kernel_regularizer=regularizers.l2(0.05))(x)\n",
    "    return prediction\n",
    "\n",
    "main_input1 = Input(shape=X_train_1.shape[1:],name='image_input1')\n",
    "main_input2 = Input(shape=X_train_2.shape[1:],name='image_input2')\n",
    "angle_input = Input(shape=(1,), name='angle_input')\n",
    "\n",
    "x1_pre=model_i(main_input1,angle_input)\n",
    "x2_pre=model_i(main_input2,angle_input)\n",
    "\n",
    "x_pre=keras.layers.concatenate([x1_pre,x2_pre])\n",
    "# x_pre=dense_block(x_pre,256)\n",
    "# x_pre=dense_block(x_pre,16)\n",
    "\n",
    "predictions = Dense(num_classes, activation='softmax',name='main_output',\n",
    "                    kernel_regularizer=regularizers.l2(0.01),\n",
    "                    kernel_initializer='glorot_normal')(x_pre)\n",
    "\n",
    "# This creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "model = Model(inputs=[main_input1,main_input2, angle_input], outputs=predictions)\n",
    "\n",
    "opt=keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#input data\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "# model.fit({'image_input1': X_train_1,'image_input2': X_train_2, 'angle_input':  X_train_plus},\n",
    "#           {'main_output': y_train_cv},\n",
    "#           validation_data=([X_valid_1,X_valid_2,X_valid_plus],y_valid),\n",
    "#           epochs=epochs, batch_size=batch_size,\n",
    "#           callbacks=[keras.callbacks.ModelCheckpoint(filepath,\n",
    "#                                                         monitor='val_acc',\n",
    "#                                                         verbose=0,\n",
    "#                                                         save_best_only=True, \n",
    "#                                                         mode='auto')])\n",
    "image_augmentation = ImageDataGenerator( rotation_range = 20,\n",
    "                                         horizontal_flip = True,\n",
    "                                         vertical_flip = True,\n",
    "                                         width_shift_range = .3,\n",
    "                                         height_shift_range =.3,\n",
    "                                         zoom_range = .1 )\n",
    "\n",
    "train_generator = generator_img_plus_new( image_augmentation, X_train_1,X_train_2,\n",
    "                                X_train_plus, y_train_cv, \n",
    "                                batch_size = batch_size)\n",
    "model.fit_generator(train_generator,epochs=epochs,\n",
    "                    validation_data=([X_valid_1,X_valid_2,X_valid_plus],y_valid),\n",
    "#                   validation_data=generator_img_angle(X_valid,X_valid_angle,y_valid,\n",
    "#                                                       batch_size,is_training=True),\n",
    "                    validation_steps=batch_num_val,\n",
    "                    workers=4,\n",
    "                    steps_per_epoch=batch_num_per_epoch,\n",
    "                    # 该回调函数将在每个epoch后保存模型到filepath\n",
    "                    callbacks=[keras.callbacks.ModelCheckpoint(filepath,\n",
    "                                                               monitor='val_acc',\n",
    "                                                               verbose=0,\n",
    "                                                               save_best_only=True, \n",
    "                                                               mode='auto')])\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate([X_valid_1,X_valid_2,X_valid_plus],y_valid, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401/401 [==============================] - 2s 4ms/step\n",
      "validation accuracy: [1.1274703568651194, 0.887780549074349]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "# Score trained model.\n",
    "scores = model.evaluate([X_valid_1,X_valid_2, X_valid_plus],y_valid, verbose=1)\n",
    "# batch_size=32\n",
    "# batch_num_val=math.ceil(X_valid.shape[0]/batch_size)\n",
    "# scores = model.evaluate_generator(generator_img_plus(X_valid, X_valid_plus, y_valid,batch_size=batch_size),\n",
    "#                                   steps=batch_num_val)\n",
    "\n",
    "print(\"validation accuracy:\",scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3.Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model_path=\"../iceberg_code/keras_iceberg_epoch_mymodel.h5\"\n",
    "model = load_model(model_path)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cv/miniconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch0 has finished!\n",
      "\n",
      "batch1 has finished!\n",
      "\n",
      "batch2 has finished!\n",
      "\n",
      "batch3 has finished!\n",
      "\n",
      "batch4 has finished!\n",
      "\n",
      "batch5 has finished!\n",
      "\n",
      "batch6 has finished!\n",
      "\n",
      "batch7 has finished!\n",
      "\n",
      "batch8 has finished!\n",
      "\n",
      "batch9 has finished!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "cut_set_num=10\n",
    "lenth_test=8424\n",
    "num_classes=2\n",
    "is_training=False\n",
    "test_path=\"../input/test_cut/\"\n",
    "batch_size=32\n",
    "\n",
    "\n",
    "predicted_test=[]\n",
    "result_max=[]\n",
    "test_id=[]\n",
    "\n",
    "\n",
    "for ci in range(cut_set_num):\n",
    "    test_pathi=test_path+\"test%d.json\"%ci\n",
    "    test_json_str = open(test_pathi, 'r').readlines()[0]\n",
    "    test=pd.read_json(test_json_str)\n",
    "    \n",
    "    #use mean of angle to replace \"na\"\n",
    "    inc_angle = test.inc_angle.replace('na',0)\n",
    "    idx=np.where(inc_angle==0)\n",
    "    inc_angle = inc_angle.drop(idx[0])\n",
    "    inc_mean=np.mean(inc_angle)\n",
    "    test.inc_angle = test.inc_angle.replace('na',inc_mean)\n",
    "#     test= test.drop(idx[0])\n",
    "#     test.inc_angle = test.inc_angle.replace('na',0)\n",
    "   \n",
    "    X_test_1,X_test_2,X_test_plus,y_test=data_normal(X_=test,y_=None,is_training=False)\n",
    "    batch_num_predic=math.ceil(X_test_1.shape[0]/batch_size)\n",
    "#     print(X_test.shape[0],batch_num_predic)\n",
    "    #发现一个问题,steps总是比我设置的多出10\n",
    "    predicted_testi=model.predict([X_test_1,X_test_2,X_test_plus])\n",
    "    \n",
    "#     predicted_testi=model.predict_generator(generator_img_angle(X11=X_test,\n",
    "#                                                                 X2=X_test_angle, \n",
    "#                                                                 Y=None,\n",
    "#                                                                 batch_size=batch_size,\n",
    "#                                                                 is_training=False),\n",
    "#                                             steps=batch_num_predic)\n",
    "    \n",
    "    test_id.extend(test[\"id\"])\n",
    "    predicted_testi=predicted_testi.reshape(predicted_testi.shape[0],2)\n",
    "    for index in range(len(predicted_testi)):\n",
    "        predicted_test.append(predicted_testi[index][1])\n",
    "    result_max.extend( np.argmax(predicted_testi, axis = 1) )\n",
    "    \n",
    "    print(\"batch%d has finished!\"%ci)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8424 8424 8424\n"
     ]
    }
   ],
   "source": [
    "# save result\n",
    "submission = pd.DataFrame()\n",
    "print(len(test_id),len(result_max),len(predicted_test))\n",
    "submission['id']=test_id\n",
    "submission['is_iceberg']=result_max\n",
    "submission.to_csv('sub.csv', index=False)\n",
    "# save probablity\n",
    "\n",
    "submission['is_iceberg']=predicted_test\n",
    "submission.to_csv('aug_plus_my_merge_model.csv', index=False,float_format=\"%.6lf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1342 (Conv2D)            (None, None, None, 3 864         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1222 (Batch (None, None, None, 3 96          conv2d_1342[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1339 (Activation)    (None, None, None, 3 0           batch_normalization_1222[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1343 (Conv2D)            (None, None, None, 3 9216        activation_1339[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1223 (Batch (None, None, None, 3 96          conv2d_1343[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1340 (Activation)    (None, None, None, 3 0           batch_normalization_1223[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1344 (Conv2D)            (None, None, None, 6 18432       activation_1340[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1224 (Batch (None, None, None, 6 192         conv2d_1344[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1341 (Activation)    (None, None, None, 6 0           batch_normalization_1224[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling2D) (None, None, None, 6 0           activation_1341[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1345 (Conv2D)            (None, None, None, 8 5120        max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1225 (Batch (None, None, None, 8 240         conv2d_1345[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1342 (Activation)    (None, None, None, 8 0           batch_normalization_1225[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1346 (Conv2D)            (None, None, None, 1 138240      activation_1342[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1226 (Batch (None, None, None, 1 576         conv2d_1346[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1343 (Activation)    (None, None, None, 1 0           batch_normalization_1226[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling2D) (None, None, None, 1 0           activation_1343[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1350 (Conv2D)            (None, None, None, 6 12288       max_pooling2d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1230 (Batch (None, None, None, 6 192         conv2d_1350[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1347 (Activation)    (None, None, None, 6 0           batch_normalization_1230[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1348 (Conv2D)            (None, None, None, 4 9216        max_pooling2d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1351 (Conv2D)            (None, None, None, 9 55296       activation_1347[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1228 (Batch (None, None, None, 4 144         conv2d_1348[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1231 (Batch (None, None, None, 9 288         conv2d_1351[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1345 (Activation)    (None, None, None, 4 0           batch_normalization_1228[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1348 (Activation)    (None, None, None, 9 0           batch_normalization_1231[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, None, None, 1 0           max_pooling2d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1347 (Conv2D)            (None, None, None, 9 18432       max_pooling2d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1349 (Conv2D)            (None, None, None, 6 76800       activation_1345[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1352 (Conv2D)            (None, None, None, 9 82944       activation_1348[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1353 (Conv2D)            (None, None, None, 6 12288       average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1227 (Batch (None, None, None, 9 288         conv2d_1347[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1229 (Batch (None, None, None, 6 192         conv2d_1349[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1232 (Batch (None, None, None, 9 288         conv2d_1352[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1233 (Batch (None, None, None, 6 192         conv2d_1353[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1344 (Activation)    (None, None, None, 9 0           batch_normalization_1227[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1346 (Activation)    (None, None, None, 6 0           batch_normalization_1229[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1349 (Activation)    (None, None, None, 9 0           batch_normalization_1232[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1350 (Activation)    (None, None, None, 6 0           batch_normalization_1233[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed_5b (Concatenate)          (None, None, None, 3 0           activation_1344[0][0]            \n",
      "                                                                 activation_1346[0][0]            \n",
      "                                                                 activation_1349[0][0]            \n",
      "                                                                 activation_1350[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1357 (Conv2D)            (None, None, None, 3 10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1237 (Batch (None, None, None, 3 96          conv2d_1357[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1354 (Activation)    (None, None, None, 3 0           batch_normalization_1237[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1355 (Conv2D)            (None, None, None, 3 10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1358 (Conv2D)            (None, None, None, 4 13824       activation_1354[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1235 (Batch (None, None, None, 3 96          conv2d_1355[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1238 (Batch (None, None, None, 4 144         conv2d_1358[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1352 (Activation)    (None, None, None, 3 0           batch_normalization_1235[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1355 (Activation)    (None, None, None, 4 0           batch_normalization_1238[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1354 (Conv2D)            (None, None, None, 3 10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1356 (Conv2D)            (None, None, None, 3 9216        activation_1352[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1359 (Conv2D)            (None, None, None, 6 27648       activation_1355[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1234 (Batch (None, None, None, 3 96          conv2d_1354[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1236 (Batch (None, None, None, 3 96          conv2d_1356[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1239 (Batch (None, None, None, 6 192         conv2d_1359[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1351 (Activation)    (None, None, None, 3 0           batch_normalization_1234[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1353 (Activation)    (None, None, None, 3 0           batch_normalization_1236[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1356 (Activation)    (None, None, None, 6 0           batch_normalization_1239[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_mixed (Concatenate)   (None, None, None, 1 0           activation_1351[0][0]            \n",
      "                                                                 activation_1353[0][0]            \n",
      "                                                                 activation_1356[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_conv (Conv2D)         (None, None, None, 3 41280       block35_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_1 (Lambda)              (None, None, None, 3 0           mixed_5b[0][0]                   \n",
      "                                                                 block35_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_ac (Activation)       (None, None, None, 3 0           block35_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1363 (Conv2D)            (None, None, None, 3 10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1243 (Batch (None, None, None, 3 96          conv2d_1363[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1360 (Activation)    (None, None, None, 3 0           batch_normalization_1243[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1361 (Conv2D)            (None, None, None, 3 10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1364 (Conv2D)            (None, None, None, 4 13824       activation_1360[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1241 (Batch (None, None, None, 3 96          conv2d_1361[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1244 (Batch (None, None, None, 4 144         conv2d_1364[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1358 (Activation)    (None, None, None, 3 0           batch_normalization_1241[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1361 (Activation)    (None, None, None, 4 0           batch_normalization_1244[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1360 (Conv2D)            (None, None, None, 3 10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1362 (Conv2D)            (None, None, None, 3 9216        activation_1358[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1365 (Conv2D)            (None, None, None, 6 27648       activation_1361[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1240 (Batch (None, None, None, 3 96          conv2d_1360[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1242 (Batch (None, None, None, 3 96          conv2d_1362[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1245 (Batch (None, None, None, 6 192         conv2d_1365[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1357 (Activation)    (None, None, None, 3 0           batch_normalization_1240[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1359 (Activation)    (None, None, None, 3 0           batch_normalization_1242[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1362 (Activation)    (None, None, None, 6 0           batch_normalization_1245[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_mixed (Concatenate)   (None, None, None, 1 0           activation_1357[0][0]            \n",
      "                                                                 activation_1359[0][0]            \n",
      "                                                                 activation_1362[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_conv (Conv2D)         (None, None, None, 3 41280       block35_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_2 (Lambda)              (None, None, None, 3 0           block35_1_ac[0][0]               \n",
      "                                                                 block35_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_ac (Activation)       (None, None, None, 3 0           block35_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1369 (Conv2D)            (None, None, None, 3 10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1249 (Batch (None, None, None, 3 96          conv2d_1369[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1366 (Activation)    (None, None, None, 3 0           batch_normalization_1249[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1367 (Conv2D)            (None, None, None, 3 10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1370 (Conv2D)            (None, None, None, 4 13824       activation_1366[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1247 (Batch (None, None, None, 3 96          conv2d_1367[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1250 (Batch (None, None, None, 4 144         conv2d_1370[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1364 (Activation)    (None, None, None, 3 0           batch_normalization_1247[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1367 (Activation)    (None, None, None, 4 0           batch_normalization_1250[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1366 (Conv2D)            (None, None, None, 3 10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1368 (Conv2D)            (None, None, None, 3 9216        activation_1364[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1371 (Conv2D)            (None, None, None, 6 27648       activation_1367[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1246 (Batch (None, None, None, 3 96          conv2d_1366[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1248 (Batch (None, None, None, 3 96          conv2d_1368[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1251 (Batch (None, None, None, 6 192         conv2d_1371[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1363 (Activation)    (None, None, None, 3 0           batch_normalization_1246[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1365 (Activation)    (None, None, None, 3 0           batch_normalization_1248[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1368 (Activation)    (None, None, None, 6 0           batch_normalization_1251[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_mixed (Concatenate)   (None, None, None, 1 0           activation_1363[0][0]            \n",
      "                                                                 activation_1365[0][0]            \n",
      "                                                                 activation_1368[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_conv (Conv2D)         (None, None, None, 3 41280       block35_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_3 (Lambda)              (None, None, None, 3 0           block35_2_ac[0][0]               \n",
      "                                                                 block35_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_ac (Activation)       (None, None, None, 3 0           block35_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1375 (Conv2D)            (None, None, None, 3 10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1255 (Batch (None, None, None, 3 96          conv2d_1375[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1372 (Activation)    (None, None, None, 3 0           batch_normalization_1255[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1373 (Conv2D)            (None, None, None, 3 10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1376 (Conv2D)            (None, None, None, 4 13824       activation_1372[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1253 (Batch (None, None, None, 3 96          conv2d_1373[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1256 (Batch (None, None, None, 4 144         conv2d_1376[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1370 (Activation)    (None, None, None, 3 0           batch_normalization_1253[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1373 (Activation)    (None, None, None, 4 0           batch_normalization_1256[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1372 (Conv2D)            (None, None, None, 3 10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1374 (Conv2D)            (None, None, None, 3 9216        activation_1370[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1377 (Conv2D)            (None, None, None, 6 27648       activation_1373[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1252 (Batch (None, None, None, 3 96          conv2d_1372[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1254 (Batch (None, None, None, 3 96          conv2d_1374[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1257 (Batch (None, None, None, 6 192         conv2d_1377[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1369 (Activation)    (None, None, None, 3 0           batch_normalization_1252[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1371 (Activation)    (None, None, None, 3 0           batch_normalization_1254[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1374 (Activation)    (None, None, None, 6 0           batch_normalization_1257[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_mixed (Concatenate)   (None, None, None, 1 0           activation_1369[0][0]            \n",
      "                                                                 activation_1371[0][0]            \n",
      "                                                                 activation_1374[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_conv (Conv2D)         (None, None, None, 3 41280       block35_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_4 (Lambda)              (None, None, None, 3 0           block35_3_ac[0][0]               \n",
      "                                                                 block35_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_ac (Activation)       (None, None, None, 3 0           block35_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1381 (Conv2D)            (None, None, None, 3 10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1261 (Batch (None, None, None, 3 96          conv2d_1381[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1378 (Activation)    (None, None, None, 3 0           batch_normalization_1261[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1379 (Conv2D)            (None, None, None, 3 10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1382 (Conv2D)            (None, None, None, 4 13824       activation_1378[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1259 (Batch (None, None, None, 3 96          conv2d_1379[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1262 (Batch (None, None, None, 4 144         conv2d_1382[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1376 (Activation)    (None, None, None, 3 0           batch_normalization_1259[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1379 (Activation)    (None, None, None, 4 0           batch_normalization_1262[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1378 (Conv2D)            (None, None, None, 3 10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1380 (Conv2D)            (None, None, None, 3 9216        activation_1376[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1383 (Conv2D)            (None, None, None, 6 27648       activation_1379[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1258 (Batch (None, None, None, 3 96          conv2d_1378[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1260 (Batch (None, None, None, 3 96          conv2d_1380[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1263 (Batch (None, None, None, 6 192         conv2d_1383[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1375 (Activation)    (None, None, None, 3 0           batch_normalization_1258[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1377 (Activation)    (None, None, None, 3 0           batch_normalization_1260[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1380 (Activation)    (None, None, None, 6 0           batch_normalization_1263[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_mixed (Concatenate)   (None, None, None, 1 0           activation_1375[0][0]            \n",
      "                                                                 activation_1377[0][0]            \n",
      "                                                                 activation_1380[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_conv (Conv2D)         (None, None, None, 3 41280       block35_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_5 (Lambda)              (None, None, None, 3 0           block35_4_ac[0][0]               \n",
      "                                                                 block35_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_ac (Activation)       (None, None, None, 3 0           block35_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1387 (Conv2D)            (None, None, None, 3 10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1267 (Batch (None, None, None, 3 96          conv2d_1387[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1384 (Activation)    (None, None, None, 3 0           batch_normalization_1267[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1385 (Conv2D)            (None, None, None, 3 10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1388 (Conv2D)            (None, None, None, 4 13824       activation_1384[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1265 (Batch (None, None, None, 3 96          conv2d_1385[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1268 (Batch (None, None, None, 4 144         conv2d_1388[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1382 (Activation)    (None, None, None, 3 0           batch_normalization_1265[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1385 (Activation)    (None, None, None, 4 0           batch_normalization_1268[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1384 (Conv2D)            (None, None, None, 3 10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1386 (Conv2D)            (None, None, None, 3 9216        activation_1382[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1389 (Conv2D)            (None, None, None, 6 27648       activation_1385[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1264 (Batch (None, None, None, 3 96          conv2d_1384[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1266 (Batch (None, None, None, 3 96          conv2d_1386[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1269 (Batch (None, None, None, 6 192         conv2d_1389[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1381 (Activation)    (None, None, None, 3 0           batch_normalization_1264[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1383 (Activation)    (None, None, None, 3 0           batch_normalization_1266[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1386 (Activation)    (None, None, None, 6 0           batch_normalization_1269[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_mixed (Concatenate)   (None, None, None, 1 0           activation_1381[0][0]            \n",
      "                                                                 activation_1383[0][0]            \n",
      "                                                                 activation_1386[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_conv (Conv2D)         (None, None, None, 3 41280       block35_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_6 (Lambda)              (None, None, None, 3 0           block35_5_ac[0][0]               \n",
      "                                                                 block35_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_ac (Activation)       (None, None, None, 3 0           block35_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1393 (Conv2D)            (None, None, None, 3 10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1273 (Batch (None, None, None, 3 96          conv2d_1393[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1390 (Activation)    (None, None, None, 3 0           batch_normalization_1273[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1391 (Conv2D)            (None, None, None, 3 10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1394 (Conv2D)            (None, None, None, 4 13824       activation_1390[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1271 (Batch (None, None, None, 3 96          conv2d_1391[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1274 (Batch (None, None, None, 4 144         conv2d_1394[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1388 (Activation)    (None, None, None, 3 0           batch_normalization_1271[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1391 (Activation)    (None, None, None, 4 0           batch_normalization_1274[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1390 (Conv2D)            (None, None, None, 3 10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1392 (Conv2D)            (None, None, None, 3 9216        activation_1388[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1395 (Conv2D)            (None, None, None, 6 27648       activation_1391[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1270 (Batch (None, None, None, 3 96          conv2d_1390[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1272 (Batch (None, None, None, 3 96          conv2d_1392[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1275 (Batch (None, None, None, 6 192         conv2d_1395[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1387 (Activation)    (None, None, None, 3 0           batch_normalization_1270[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1389 (Activation)    (None, None, None, 3 0           batch_normalization_1272[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1392 (Activation)    (None, None, None, 6 0           batch_normalization_1275[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_mixed (Concatenate)   (None, None, None, 1 0           activation_1387[0][0]            \n",
      "                                                                 activation_1389[0][0]            \n",
      "                                                                 activation_1392[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_conv (Conv2D)         (None, None, None, 3 41280       block35_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_7 (Lambda)              (None, None, None, 3 0           block35_6_ac[0][0]               \n",
      "                                                                 block35_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_ac (Activation)       (None, None, None, 3 0           block35_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1399 (Conv2D)            (None, None, None, 3 10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1279 (Batch (None, None, None, 3 96          conv2d_1399[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1396 (Activation)    (None, None, None, 3 0           batch_normalization_1279[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1397 (Conv2D)            (None, None, None, 3 10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1400 (Conv2D)            (None, None, None, 4 13824       activation_1396[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1277 (Batch (None, None, None, 3 96          conv2d_1397[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1280 (Batch (None, None, None, 4 144         conv2d_1400[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1394 (Activation)    (None, None, None, 3 0           batch_normalization_1277[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1397 (Activation)    (None, None, None, 4 0           batch_normalization_1280[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1396 (Conv2D)            (None, None, None, 3 10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1398 (Conv2D)            (None, None, None, 3 9216        activation_1394[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1401 (Conv2D)            (None, None, None, 6 27648       activation_1397[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1276 (Batch (None, None, None, 3 96          conv2d_1396[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1278 (Batch (None, None, None, 3 96          conv2d_1398[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1281 (Batch (None, None, None, 6 192         conv2d_1401[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1393 (Activation)    (None, None, None, 3 0           batch_normalization_1276[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1395 (Activation)    (None, None, None, 3 0           batch_normalization_1278[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1398 (Activation)    (None, None, None, 6 0           batch_normalization_1281[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_mixed (Concatenate)   (None, None, None, 1 0           activation_1393[0][0]            \n",
      "                                                                 activation_1395[0][0]            \n",
      "                                                                 activation_1398[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_conv (Conv2D)         (None, None, None, 3 41280       block35_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_8 (Lambda)              (None, None, None, 3 0           block35_7_ac[0][0]               \n",
      "                                                                 block35_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_ac (Activation)       (None, None, None, 3 0           block35_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1405 (Conv2D)            (None, None, None, 3 10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1285 (Batch (None, None, None, 3 96          conv2d_1405[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1402 (Activation)    (None, None, None, 3 0           batch_normalization_1285[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1403 (Conv2D)            (None, None, None, 3 10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1406 (Conv2D)            (None, None, None, 4 13824       activation_1402[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1283 (Batch (None, None, None, 3 96          conv2d_1403[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1286 (Batch (None, None, None, 4 144         conv2d_1406[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1400 (Activation)    (None, None, None, 3 0           batch_normalization_1283[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1403 (Activation)    (None, None, None, 4 0           batch_normalization_1286[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1402 (Conv2D)            (None, None, None, 3 10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1404 (Conv2D)            (None, None, None, 3 9216        activation_1400[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1407 (Conv2D)            (None, None, None, 6 27648       activation_1403[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1282 (Batch (None, None, None, 3 96          conv2d_1402[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1284 (Batch (None, None, None, 3 96          conv2d_1404[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1287 (Batch (None, None, None, 6 192         conv2d_1407[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1399 (Activation)    (None, None, None, 3 0           batch_normalization_1282[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1401 (Activation)    (None, None, None, 3 0           batch_normalization_1284[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1404 (Activation)    (None, None, None, 6 0           batch_normalization_1287[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_mixed (Concatenate)   (None, None, None, 1 0           activation_1399[0][0]            \n",
      "                                                                 activation_1401[0][0]            \n",
      "                                                                 activation_1404[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_conv (Conv2D)         (None, None, None, 3 41280       block35_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_9 (Lambda)              (None, None, None, 3 0           block35_8_ac[0][0]               \n",
      "                                                                 block35_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_ac (Activation)       (None, None, None, 3 0           block35_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1411 (Conv2D)            (None, None, None, 3 10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1291 (Batch (None, None, None, 3 96          conv2d_1411[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1408 (Activation)    (None, None, None, 3 0           batch_normalization_1291[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1409 (Conv2D)            (None, None, None, 3 10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1412 (Conv2D)            (None, None, None, 4 13824       activation_1408[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1289 (Batch (None, None, None, 3 96          conv2d_1409[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1292 (Batch (None, None, None, 4 144         conv2d_1412[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1406 (Activation)    (None, None, None, 3 0           batch_normalization_1289[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1409 (Activation)    (None, None, None, 4 0           batch_normalization_1292[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1408 (Conv2D)            (None, None, None, 3 10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1410 (Conv2D)            (None, None, None, 3 9216        activation_1406[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1413 (Conv2D)            (None, None, None, 6 27648       activation_1409[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1288 (Batch (None, None, None, 3 96          conv2d_1408[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1290 (Batch (None, None, None, 3 96          conv2d_1410[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1293 (Batch (None, None, None, 6 192         conv2d_1413[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1405 (Activation)    (None, None, None, 3 0           batch_normalization_1288[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1407 (Activation)    (None, None, None, 3 0           batch_normalization_1290[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1410 (Activation)    (None, None, None, 6 0           batch_normalization_1293[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_mixed (Concatenate)  (None, None, None, 1 0           activation_1405[0][0]            \n",
      "                                                                 activation_1407[0][0]            \n",
      "                                                                 activation_1410[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_conv (Conv2D)        (None, None, None, 3 41280       block35_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block35_10 (Lambda)             (None, None, None, 3 0           block35_9_ac[0][0]               \n",
      "                                                                 block35_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_ac (Activation)      (None, None, None, 3 0           block35_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1415 (Conv2D)            (None, None, None, 2 81920       block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1295 (Batch (None, None, None, 2 768         conv2d_1415[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1412 (Activation)    (None, None, None, 2 0           batch_normalization_1295[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1416 (Conv2D)            (None, None, None, 2 589824      activation_1412[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1296 (Batch (None, None, None, 2 768         conv2d_1416[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1413 (Activation)    (None, None, None, 2 0           batch_normalization_1296[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1414 (Conv2D)            (None, None, None, 3 1105920     block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1417 (Conv2D)            (None, None, None, 3 884736      activation_1413[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1294 (Batch (None, None, None, 3 1152        conv2d_1414[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1297 (Batch (None, None, None, 3 1152        conv2d_1417[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1411 (Activation)    (None, None, None, 3 0           batch_normalization_1294[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1414 (Activation)    (None, None, None, 3 0           batch_normalization_1297[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling2D) (None, None, None, 3 0           block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_6a (Concatenate)          (None, None, None, 1 0           activation_1411[0][0]            \n",
      "                                                                 activation_1414[0][0]            \n",
      "                                                                 max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1419 (Conv2D)            (None, None, None, 1 139264      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1299 (Batch (None, None, None, 1 384         conv2d_1419[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1416 (Activation)    (None, None, None, 1 0           batch_normalization_1299[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1420 (Conv2D)            (None, None, None, 1 143360      activation_1416[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1300 (Batch (None, None, None, 1 480         conv2d_1420[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1417 (Activation)    (None, None, None, 1 0           batch_normalization_1300[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1418 (Conv2D)            (None, None, None, 1 208896      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1421 (Conv2D)            (None, None, None, 1 215040      activation_1417[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1298 (Batch (None, None, None, 1 576         conv2d_1418[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1301 (Batch (None, None, None, 1 576         conv2d_1421[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1415 (Activation)    (None, None, None, 1 0           batch_normalization_1298[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1418 (Activation)    (None, None, None, 1 0           batch_normalization_1301[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_mixed (Concatenate)   (None, None, None, 3 0           activation_1415[0][0]            \n",
      "                                                                 activation_1418[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_conv (Conv2D)         (None, None, None, 1 418880      block17_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_1 (Lambda)              (None, None, None, 1 0           mixed_6a[0][0]                   \n",
      "                                                                 block17_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_ac (Activation)       (None, None, None, 1 0           block17_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1423 (Conv2D)            (None, None, None, 1 139264      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1303 (Batch (None, None, None, 1 384         conv2d_1423[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1420 (Activation)    (None, None, None, 1 0           batch_normalization_1303[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1424 (Conv2D)            (None, None, None, 1 143360      activation_1420[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1304 (Batch (None, None, None, 1 480         conv2d_1424[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1421 (Activation)    (None, None, None, 1 0           batch_normalization_1304[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1422 (Conv2D)            (None, None, None, 1 208896      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1425 (Conv2D)            (None, None, None, 1 215040      activation_1421[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1302 (Batch (None, None, None, 1 576         conv2d_1422[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1305 (Batch (None, None, None, 1 576         conv2d_1425[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1419 (Activation)    (None, None, None, 1 0           batch_normalization_1302[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1422 (Activation)    (None, None, None, 1 0           batch_normalization_1305[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_mixed (Concatenate)   (None, None, None, 3 0           activation_1419[0][0]            \n",
      "                                                                 activation_1422[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_conv (Conv2D)         (None, None, None, 1 418880      block17_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_2 (Lambda)              (None, None, None, 1 0           block17_1_ac[0][0]               \n",
      "                                                                 block17_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_ac (Activation)       (None, None, None, 1 0           block17_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1427 (Conv2D)            (None, None, None, 1 139264      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1307 (Batch (None, None, None, 1 384         conv2d_1427[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1424 (Activation)    (None, None, None, 1 0           batch_normalization_1307[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1428 (Conv2D)            (None, None, None, 1 143360      activation_1424[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1308 (Batch (None, None, None, 1 480         conv2d_1428[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1425 (Activation)    (None, None, None, 1 0           batch_normalization_1308[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1426 (Conv2D)            (None, None, None, 1 208896      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1429 (Conv2D)            (None, None, None, 1 215040      activation_1425[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1306 (Batch (None, None, None, 1 576         conv2d_1426[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1309 (Batch (None, None, None, 1 576         conv2d_1429[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1423 (Activation)    (None, None, None, 1 0           batch_normalization_1306[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1426 (Activation)    (None, None, None, 1 0           batch_normalization_1309[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_mixed (Concatenate)   (None, None, None, 3 0           activation_1423[0][0]            \n",
      "                                                                 activation_1426[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_conv (Conv2D)         (None, None, None, 1 418880      block17_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_3 (Lambda)              (None, None, None, 1 0           block17_2_ac[0][0]               \n",
      "                                                                 block17_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_ac (Activation)       (None, None, None, 1 0           block17_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1431 (Conv2D)            (None, None, None, 1 139264      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1311 (Batch (None, None, None, 1 384         conv2d_1431[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1428 (Activation)    (None, None, None, 1 0           batch_normalization_1311[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1432 (Conv2D)            (None, None, None, 1 143360      activation_1428[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1312 (Batch (None, None, None, 1 480         conv2d_1432[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1429 (Activation)    (None, None, None, 1 0           batch_normalization_1312[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1430 (Conv2D)            (None, None, None, 1 208896      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1433 (Conv2D)            (None, None, None, 1 215040      activation_1429[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1310 (Batch (None, None, None, 1 576         conv2d_1430[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1313 (Batch (None, None, None, 1 576         conv2d_1433[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1427 (Activation)    (None, None, None, 1 0           batch_normalization_1310[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1430 (Activation)    (None, None, None, 1 0           batch_normalization_1313[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_mixed (Concatenate)   (None, None, None, 3 0           activation_1427[0][0]            \n",
      "                                                                 activation_1430[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_conv (Conv2D)         (None, None, None, 1 418880      block17_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_4 (Lambda)              (None, None, None, 1 0           block17_3_ac[0][0]               \n",
      "                                                                 block17_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_ac (Activation)       (None, None, None, 1 0           block17_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1435 (Conv2D)            (None, None, None, 1 139264      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1315 (Batch (None, None, None, 1 384         conv2d_1435[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1432 (Activation)    (None, None, None, 1 0           batch_normalization_1315[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1436 (Conv2D)            (None, None, None, 1 143360      activation_1432[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1316 (Batch (None, None, None, 1 480         conv2d_1436[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1433 (Activation)    (None, None, None, 1 0           batch_normalization_1316[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1434 (Conv2D)            (None, None, None, 1 208896      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1437 (Conv2D)            (None, None, None, 1 215040      activation_1433[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1314 (Batch (None, None, None, 1 576         conv2d_1434[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1317 (Batch (None, None, None, 1 576         conv2d_1437[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1431 (Activation)    (None, None, None, 1 0           batch_normalization_1314[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1434 (Activation)    (None, None, None, 1 0           batch_normalization_1317[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_mixed (Concatenate)   (None, None, None, 3 0           activation_1431[0][0]            \n",
      "                                                                 activation_1434[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_conv (Conv2D)         (None, None, None, 1 418880      block17_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_5 (Lambda)              (None, None, None, 1 0           block17_4_ac[0][0]               \n",
      "                                                                 block17_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_ac (Activation)       (None, None, None, 1 0           block17_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1439 (Conv2D)            (None, None, None, 1 139264      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1319 (Batch (None, None, None, 1 384         conv2d_1439[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1436 (Activation)    (None, None, None, 1 0           batch_normalization_1319[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1440 (Conv2D)            (None, None, None, 1 143360      activation_1436[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1320 (Batch (None, None, None, 1 480         conv2d_1440[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1437 (Activation)    (None, None, None, 1 0           batch_normalization_1320[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1438 (Conv2D)            (None, None, None, 1 208896      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1441 (Conv2D)            (None, None, None, 1 215040      activation_1437[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1318 (Batch (None, None, None, 1 576         conv2d_1438[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1321 (Batch (None, None, None, 1 576         conv2d_1441[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1435 (Activation)    (None, None, None, 1 0           batch_normalization_1318[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1438 (Activation)    (None, None, None, 1 0           batch_normalization_1321[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_mixed (Concatenate)   (None, None, None, 3 0           activation_1435[0][0]            \n",
      "                                                                 activation_1438[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_conv (Conv2D)         (None, None, None, 1 418880      block17_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_6 (Lambda)              (None, None, None, 1 0           block17_5_ac[0][0]               \n",
      "                                                                 block17_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_ac (Activation)       (None, None, None, 1 0           block17_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1443 (Conv2D)            (None, None, None, 1 139264      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1323 (Batch (None, None, None, 1 384         conv2d_1443[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1440 (Activation)    (None, None, None, 1 0           batch_normalization_1323[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1444 (Conv2D)            (None, None, None, 1 143360      activation_1440[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1324 (Batch (None, None, None, 1 480         conv2d_1444[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1441 (Activation)    (None, None, None, 1 0           batch_normalization_1324[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1442 (Conv2D)            (None, None, None, 1 208896      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1445 (Conv2D)            (None, None, None, 1 215040      activation_1441[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1322 (Batch (None, None, None, 1 576         conv2d_1442[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1325 (Batch (None, None, None, 1 576         conv2d_1445[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1439 (Activation)    (None, None, None, 1 0           batch_normalization_1322[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1442 (Activation)    (None, None, None, 1 0           batch_normalization_1325[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_mixed (Concatenate)   (None, None, None, 3 0           activation_1439[0][0]            \n",
      "                                                                 activation_1442[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_conv (Conv2D)         (None, None, None, 1 418880      block17_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_7 (Lambda)              (None, None, None, 1 0           block17_6_ac[0][0]               \n",
      "                                                                 block17_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_ac (Activation)       (None, None, None, 1 0           block17_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1447 (Conv2D)            (None, None, None, 1 139264      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1327 (Batch (None, None, None, 1 384         conv2d_1447[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1444 (Activation)    (None, None, None, 1 0           batch_normalization_1327[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1448 (Conv2D)            (None, None, None, 1 143360      activation_1444[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1328 (Batch (None, None, None, 1 480         conv2d_1448[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1445 (Activation)    (None, None, None, 1 0           batch_normalization_1328[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1446 (Conv2D)            (None, None, None, 1 208896      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1449 (Conv2D)            (None, None, None, 1 215040      activation_1445[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1326 (Batch (None, None, None, 1 576         conv2d_1446[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1329 (Batch (None, None, None, 1 576         conv2d_1449[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1443 (Activation)    (None, None, None, 1 0           batch_normalization_1326[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1446 (Activation)    (None, None, None, 1 0           batch_normalization_1329[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_mixed (Concatenate)   (None, None, None, 3 0           activation_1443[0][0]            \n",
      "                                                                 activation_1446[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_conv (Conv2D)         (None, None, None, 1 418880      block17_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_8 (Lambda)              (None, None, None, 1 0           block17_7_ac[0][0]               \n",
      "                                                                 block17_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_ac (Activation)       (None, None, None, 1 0           block17_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1451 (Conv2D)            (None, None, None, 1 139264      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1331 (Batch (None, None, None, 1 384         conv2d_1451[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1448 (Activation)    (None, None, None, 1 0           batch_normalization_1331[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1452 (Conv2D)            (None, None, None, 1 143360      activation_1448[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1332 (Batch (None, None, None, 1 480         conv2d_1452[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1449 (Activation)    (None, None, None, 1 0           batch_normalization_1332[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1450 (Conv2D)            (None, None, None, 1 208896      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1453 (Conv2D)            (None, None, None, 1 215040      activation_1449[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1330 (Batch (None, None, None, 1 576         conv2d_1450[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1333 (Batch (None, None, None, 1 576         conv2d_1453[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1447 (Activation)    (None, None, None, 1 0           batch_normalization_1330[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1450 (Activation)    (None, None, None, 1 0           batch_normalization_1333[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_mixed (Concatenate)   (None, None, None, 3 0           activation_1447[0][0]            \n",
      "                                                                 activation_1450[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_conv (Conv2D)         (None, None, None, 1 418880      block17_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_9 (Lambda)              (None, None, None, 1 0           block17_8_ac[0][0]               \n",
      "                                                                 block17_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_ac (Activation)       (None, None, None, 1 0           block17_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1455 (Conv2D)            (None, None, None, 1 139264      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1335 (Batch (None, None, None, 1 384         conv2d_1455[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1452 (Activation)    (None, None, None, 1 0           batch_normalization_1335[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1456 (Conv2D)            (None, None, None, 1 143360      activation_1452[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1336 (Batch (None, None, None, 1 480         conv2d_1456[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1453 (Activation)    (None, None, None, 1 0           batch_normalization_1336[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1454 (Conv2D)            (None, None, None, 1 208896      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1457 (Conv2D)            (None, None, None, 1 215040      activation_1453[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1334 (Batch (None, None, None, 1 576         conv2d_1454[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1337 (Batch (None, None, None, 1 576         conv2d_1457[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1451 (Activation)    (None, None, None, 1 0           batch_normalization_1334[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1454 (Activation)    (None, None, None, 1 0           batch_normalization_1337[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_mixed (Concatenate)  (None, None, None, 3 0           activation_1451[0][0]            \n",
      "                                                                 activation_1454[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_conv (Conv2D)        (None, None, None, 1 418880      block17_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_10 (Lambda)             (None, None, None, 1 0           block17_9_ac[0][0]               \n",
      "                                                                 block17_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_ac (Activation)      (None, None, None, 1 0           block17_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1459 (Conv2D)            (None, None, None, 1 139264      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1339 (Batch (None, None, None, 1 384         conv2d_1459[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1456 (Activation)    (None, None, None, 1 0           batch_normalization_1339[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1460 (Conv2D)            (None, None, None, 1 143360      activation_1456[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1340 (Batch (None, None, None, 1 480         conv2d_1460[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1457 (Activation)    (None, None, None, 1 0           batch_normalization_1340[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1458 (Conv2D)            (None, None, None, 1 208896      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1461 (Conv2D)            (None, None, None, 1 215040      activation_1457[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1338 (Batch (None, None, None, 1 576         conv2d_1458[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1341 (Batch (None, None, None, 1 576         conv2d_1461[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1455 (Activation)    (None, None, None, 1 0           batch_normalization_1338[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1458 (Activation)    (None, None, None, 1 0           batch_normalization_1341[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_mixed (Concatenate)  (None, None, None, 3 0           activation_1455[0][0]            \n",
      "                                                                 activation_1458[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_conv (Conv2D)        (None, None, None, 1 418880      block17_11_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_11 (Lambda)             (None, None, None, 1 0           block17_10_ac[0][0]              \n",
      "                                                                 block17_11_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_ac (Activation)      (None, None, None, 1 0           block17_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1463 (Conv2D)            (None, None, None, 1 139264      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1343 (Batch (None, None, None, 1 384         conv2d_1463[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1460 (Activation)    (None, None, None, 1 0           batch_normalization_1343[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1464 (Conv2D)            (None, None, None, 1 143360      activation_1460[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1344 (Batch (None, None, None, 1 480         conv2d_1464[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1461 (Activation)    (None, None, None, 1 0           batch_normalization_1344[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1462 (Conv2D)            (None, None, None, 1 208896      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1465 (Conv2D)            (None, None, None, 1 215040      activation_1461[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1342 (Batch (None, None, None, 1 576         conv2d_1462[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1345 (Batch (None, None, None, 1 576         conv2d_1465[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1459 (Activation)    (None, None, None, 1 0           batch_normalization_1342[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1462 (Activation)    (None, None, None, 1 0           batch_normalization_1345[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_mixed (Concatenate)  (None, None, None, 3 0           activation_1459[0][0]            \n",
      "                                                                 activation_1462[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_conv (Conv2D)        (None, None, None, 1 418880      block17_12_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_12 (Lambda)             (None, None, None, 1 0           block17_11_ac[0][0]              \n",
      "                                                                 block17_12_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_ac (Activation)      (None, None, None, 1 0           block17_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1467 (Conv2D)            (None, None, None, 1 139264      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1347 (Batch (None, None, None, 1 384         conv2d_1467[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1464 (Activation)    (None, None, None, 1 0           batch_normalization_1347[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1468 (Conv2D)            (None, None, None, 1 143360      activation_1464[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1348 (Batch (None, None, None, 1 480         conv2d_1468[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1465 (Activation)    (None, None, None, 1 0           batch_normalization_1348[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1466 (Conv2D)            (None, None, None, 1 208896      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1469 (Conv2D)            (None, None, None, 1 215040      activation_1465[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1346 (Batch (None, None, None, 1 576         conv2d_1466[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1349 (Batch (None, None, None, 1 576         conv2d_1469[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1463 (Activation)    (None, None, None, 1 0           batch_normalization_1346[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1466 (Activation)    (None, None, None, 1 0           batch_normalization_1349[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_mixed (Concatenate)  (None, None, None, 3 0           activation_1463[0][0]            \n",
      "                                                                 activation_1466[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_conv (Conv2D)        (None, None, None, 1 418880      block17_13_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_13 (Lambda)             (None, None, None, 1 0           block17_12_ac[0][0]              \n",
      "                                                                 block17_13_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_ac (Activation)      (None, None, None, 1 0           block17_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1471 (Conv2D)            (None, None, None, 1 139264      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1351 (Batch (None, None, None, 1 384         conv2d_1471[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1468 (Activation)    (None, None, None, 1 0           batch_normalization_1351[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1472 (Conv2D)            (None, None, None, 1 143360      activation_1468[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1352 (Batch (None, None, None, 1 480         conv2d_1472[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1469 (Activation)    (None, None, None, 1 0           batch_normalization_1352[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1470 (Conv2D)            (None, None, None, 1 208896      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1473 (Conv2D)            (None, None, None, 1 215040      activation_1469[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1350 (Batch (None, None, None, 1 576         conv2d_1470[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1353 (Batch (None, None, None, 1 576         conv2d_1473[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1467 (Activation)    (None, None, None, 1 0           batch_normalization_1350[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1470 (Activation)    (None, None, None, 1 0           batch_normalization_1353[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_mixed (Concatenate)  (None, None, None, 3 0           activation_1467[0][0]            \n",
      "                                                                 activation_1470[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_conv (Conv2D)        (None, None, None, 1 418880      block17_14_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_14 (Lambda)             (None, None, None, 1 0           block17_13_ac[0][0]              \n",
      "                                                                 block17_14_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_ac (Activation)      (None, None, None, 1 0           block17_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1475 (Conv2D)            (None, None, None, 1 139264      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1355 (Batch (None, None, None, 1 384         conv2d_1475[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1472 (Activation)    (None, None, None, 1 0           batch_normalization_1355[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1476 (Conv2D)            (None, None, None, 1 143360      activation_1472[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1356 (Batch (None, None, None, 1 480         conv2d_1476[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1473 (Activation)    (None, None, None, 1 0           batch_normalization_1356[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1474 (Conv2D)            (None, None, None, 1 208896      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1477 (Conv2D)            (None, None, None, 1 215040      activation_1473[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1354 (Batch (None, None, None, 1 576         conv2d_1474[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1357 (Batch (None, None, None, 1 576         conv2d_1477[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1471 (Activation)    (None, None, None, 1 0           batch_normalization_1354[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1474 (Activation)    (None, None, None, 1 0           batch_normalization_1357[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_mixed (Concatenate)  (None, None, None, 3 0           activation_1471[0][0]            \n",
      "                                                                 activation_1474[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_conv (Conv2D)        (None, None, None, 1 418880      block17_15_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_15 (Lambda)             (None, None, None, 1 0           block17_14_ac[0][0]              \n",
      "                                                                 block17_15_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_ac (Activation)      (None, None, None, 1 0           block17_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1479 (Conv2D)            (None, None, None, 1 139264      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1359 (Batch (None, None, None, 1 384         conv2d_1479[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1476 (Activation)    (None, None, None, 1 0           batch_normalization_1359[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1480 (Conv2D)            (None, None, None, 1 143360      activation_1476[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1360 (Batch (None, None, None, 1 480         conv2d_1480[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1477 (Activation)    (None, None, None, 1 0           batch_normalization_1360[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1478 (Conv2D)            (None, None, None, 1 208896      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1481 (Conv2D)            (None, None, None, 1 215040      activation_1477[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1358 (Batch (None, None, None, 1 576         conv2d_1478[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1361 (Batch (None, None, None, 1 576         conv2d_1481[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1475 (Activation)    (None, None, None, 1 0           batch_normalization_1358[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1478 (Activation)    (None, None, None, 1 0           batch_normalization_1361[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_mixed (Concatenate)  (None, None, None, 3 0           activation_1475[0][0]            \n",
      "                                                                 activation_1478[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_conv (Conv2D)        (None, None, None, 1 418880      block17_16_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_16 (Lambda)             (None, None, None, 1 0           block17_15_ac[0][0]              \n",
      "                                                                 block17_16_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_ac (Activation)      (None, None, None, 1 0           block17_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1483 (Conv2D)            (None, None, None, 1 139264      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1363 (Batch (None, None, None, 1 384         conv2d_1483[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1480 (Activation)    (None, None, None, 1 0           batch_normalization_1363[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1484 (Conv2D)            (None, None, None, 1 143360      activation_1480[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1364 (Batch (None, None, None, 1 480         conv2d_1484[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1481 (Activation)    (None, None, None, 1 0           batch_normalization_1364[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1482 (Conv2D)            (None, None, None, 1 208896      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1485 (Conv2D)            (None, None, None, 1 215040      activation_1481[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1362 (Batch (None, None, None, 1 576         conv2d_1482[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1365 (Batch (None, None, None, 1 576         conv2d_1485[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1479 (Activation)    (None, None, None, 1 0           batch_normalization_1362[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1482 (Activation)    (None, None, None, 1 0           batch_normalization_1365[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_mixed (Concatenate)  (None, None, None, 3 0           activation_1479[0][0]            \n",
      "                                                                 activation_1482[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_conv (Conv2D)        (None, None, None, 1 418880      block17_17_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_17 (Lambda)             (None, None, None, 1 0           block17_16_ac[0][0]              \n",
      "                                                                 block17_17_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_ac (Activation)      (None, None, None, 1 0           block17_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1487 (Conv2D)            (None, None, None, 1 139264      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1367 (Batch (None, None, None, 1 384         conv2d_1487[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1484 (Activation)    (None, None, None, 1 0           batch_normalization_1367[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1488 (Conv2D)            (None, None, None, 1 143360      activation_1484[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1368 (Batch (None, None, None, 1 480         conv2d_1488[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1485 (Activation)    (None, None, None, 1 0           batch_normalization_1368[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1486 (Conv2D)            (None, None, None, 1 208896      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1489 (Conv2D)            (None, None, None, 1 215040      activation_1485[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1366 (Batch (None, None, None, 1 576         conv2d_1486[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1369 (Batch (None, None, None, 1 576         conv2d_1489[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1483 (Activation)    (None, None, None, 1 0           batch_normalization_1366[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1486 (Activation)    (None, None, None, 1 0           batch_normalization_1369[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_mixed (Concatenate)  (None, None, None, 3 0           activation_1483[0][0]            \n",
      "                                                                 activation_1486[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_conv (Conv2D)        (None, None, None, 1 418880      block17_18_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_18 (Lambda)             (None, None, None, 1 0           block17_17_ac[0][0]              \n",
      "                                                                 block17_18_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_ac (Activation)      (None, None, None, 1 0           block17_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1491 (Conv2D)            (None, None, None, 1 139264      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1371 (Batch (None, None, None, 1 384         conv2d_1491[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1488 (Activation)    (None, None, None, 1 0           batch_normalization_1371[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1492 (Conv2D)            (None, None, None, 1 143360      activation_1488[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1372 (Batch (None, None, None, 1 480         conv2d_1492[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1489 (Activation)    (None, None, None, 1 0           batch_normalization_1372[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1490 (Conv2D)            (None, None, None, 1 208896      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1493 (Conv2D)            (None, None, None, 1 215040      activation_1489[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1370 (Batch (None, None, None, 1 576         conv2d_1490[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1373 (Batch (None, None, None, 1 576         conv2d_1493[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1487 (Activation)    (None, None, None, 1 0           batch_normalization_1370[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1490 (Activation)    (None, None, None, 1 0           batch_normalization_1373[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_mixed (Concatenate)  (None, None, None, 3 0           activation_1487[0][0]            \n",
      "                                                                 activation_1490[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_conv (Conv2D)        (None, None, None, 1 418880      block17_19_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_19 (Lambda)             (None, None, None, 1 0           block17_18_ac[0][0]              \n",
      "                                                                 block17_19_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_ac (Activation)      (None, None, None, 1 0           block17_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1495 (Conv2D)            (None, None, None, 1 139264      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1375 (Batch (None, None, None, 1 384         conv2d_1495[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1492 (Activation)    (None, None, None, 1 0           batch_normalization_1375[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1496 (Conv2D)            (None, None, None, 1 143360      activation_1492[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1376 (Batch (None, None, None, 1 480         conv2d_1496[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1493 (Activation)    (None, None, None, 1 0           batch_normalization_1376[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1494 (Conv2D)            (None, None, None, 1 208896      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1497 (Conv2D)            (None, None, None, 1 215040      activation_1493[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1374 (Batch (None, None, None, 1 576         conv2d_1494[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1377 (Batch (None, None, None, 1 576         conv2d_1497[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1491 (Activation)    (None, None, None, 1 0           batch_normalization_1374[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1494 (Activation)    (None, None, None, 1 0           batch_normalization_1377[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_mixed (Concatenate)  (None, None, None, 3 0           activation_1491[0][0]            \n",
      "                                                                 activation_1494[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_conv (Conv2D)        (None, None, None, 1 418880      block17_20_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_20 (Lambda)             (None, None, None, 1 0           block17_19_ac[0][0]              \n",
      "                                                                 block17_20_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_ac (Activation)      (None, None, None, 1 0           block17_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1502 (Conv2D)            (None, None, None, 2 278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1382 (Batch (None, None, None, 2 768         conv2d_1502[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1499 (Activation)    (None, None, None, 2 0           batch_normalization_1382[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1498 (Conv2D)            (None, None, None, 2 278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1500 (Conv2D)            (None, None, None, 2 278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1503 (Conv2D)            (None, None, None, 2 663552      activation_1499[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1378 (Batch (None, None, None, 2 768         conv2d_1498[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1380 (Batch (None, None, None, 2 768         conv2d_1500[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1383 (Batch (None, None, None, 2 864         conv2d_1503[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1495 (Activation)    (None, None, None, 2 0           batch_normalization_1378[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1497 (Activation)    (None, None, None, 2 0           batch_normalization_1380[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1500 (Activation)    (None, None, None, 2 0           batch_normalization_1383[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1499 (Conv2D)            (None, None, None, 3 884736      activation_1495[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1501 (Conv2D)            (None, None, None, 2 663552      activation_1497[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1504 (Conv2D)            (None, None, None, 3 829440      activation_1500[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1379 (Batch (None, None, None, 3 1152        conv2d_1499[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1381 (Batch (None, None, None, 2 864         conv2d_1501[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1384 (Batch (None, None, None, 3 960         conv2d_1504[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1496 (Activation)    (None, None, None, 3 0           batch_normalization_1379[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1498 (Activation)    (None, None, None, 2 0           batch_normalization_1381[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1501 (Activation)    (None, None, None, 3 0           batch_normalization_1384[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling2D) (None, None, None, 1 0           block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_7a (Concatenate)          (None, None, None, 2 0           activation_1496[0][0]            \n",
      "                                                                 activation_1498[0][0]            \n",
      "                                                                 activation_1501[0][0]            \n",
      "                                                                 max_pooling2d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1506 (Conv2D)            (None, None, None, 1 399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1386 (Batch (None, None, None, 1 576         conv2d_1506[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1503 (Activation)    (None, None, None, 1 0           batch_normalization_1386[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1507 (Conv2D)            (None, None, None, 2 129024      activation_1503[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1387 (Batch (None, None, None, 2 672         conv2d_1507[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1504 (Activation)    (None, None, None, 2 0           batch_normalization_1387[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1505 (Conv2D)            (None, None, None, 1 399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1508 (Conv2D)            (None, None, None, 2 172032      activation_1504[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1385 (Batch (None, None, None, 1 576         conv2d_1505[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1388 (Batch (None, None, None, 2 768         conv2d_1508[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1502 (Activation)    (None, None, None, 1 0           batch_normalization_1385[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1505 (Activation)    (None, None, None, 2 0           batch_normalization_1388[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_mixed (Concatenate)    (None, None, None, 4 0           activation_1502[0][0]            \n",
      "                                                                 activation_1505[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_conv (Conv2D)          (None, None, None, 2 933920      block8_1_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1 (Lambda)               (None, None, None, 2 0           mixed_7a[0][0]                   \n",
      "                                                                 block8_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_ac (Activation)        (None, None, None, 2 0           block8_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1510 (Conv2D)            (None, None, None, 1 399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1390 (Batch (None, None, None, 1 576         conv2d_1510[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1507 (Activation)    (None, None, None, 1 0           batch_normalization_1390[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1511 (Conv2D)            (None, None, None, 2 129024      activation_1507[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1391 (Batch (None, None, None, 2 672         conv2d_1511[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1508 (Activation)    (None, None, None, 2 0           batch_normalization_1391[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1509 (Conv2D)            (None, None, None, 1 399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1512 (Conv2D)            (None, None, None, 2 172032      activation_1508[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1389 (Batch (None, None, None, 1 576         conv2d_1509[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1392 (Batch (None, None, None, 2 768         conv2d_1512[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1506 (Activation)    (None, None, None, 1 0           batch_normalization_1389[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1509 (Activation)    (None, None, None, 2 0           batch_normalization_1392[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_mixed (Concatenate)    (None, None, None, 4 0           activation_1506[0][0]            \n",
      "                                                                 activation_1509[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_conv (Conv2D)          (None, None, None, 2 933920      block8_2_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2 (Lambda)               (None, None, None, 2 0           block8_1_ac[0][0]                \n",
      "                                                                 block8_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_ac (Activation)        (None, None, None, 2 0           block8_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1514 (Conv2D)            (None, None, None, 1 399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1394 (Batch (None, None, None, 1 576         conv2d_1514[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1511 (Activation)    (None, None, None, 1 0           batch_normalization_1394[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1515 (Conv2D)            (None, None, None, 2 129024      activation_1511[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1395 (Batch (None, None, None, 2 672         conv2d_1515[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1512 (Activation)    (None, None, None, 2 0           batch_normalization_1395[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1513 (Conv2D)            (None, None, None, 1 399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1516 (Conv2D)            (None, None, None, 2 172032      activation_1512[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1393 (Batch (None, None, None, 1 576         conv2d_1513[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1396 (Batch (None, None, None, 2 768         conv2d_1516[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1510 (Activation)    (None, None, None, 1 0           batch_normalization_1393[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1513 (Activation)    (None, None, None, 2 0           batch_normalization_1396[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_mixed (Concatenate)    (None, None, None, 4 0           activation_1510[0][0]            \n",
      "                                                                 activation_1513[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_conv (Conv2D)          (None, None, None, 2 933920      block8_3_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3 (Lambda)               (None, None, None, 2 0           block8_2_ac[0][0]                \n",
      "                                                                 block8_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_ac (Activation)        (None, None, None, 2 0           block8_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1518 (Conv2D)            (None, None, None, 1 399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1398 (Batch (None, None, None, 1 576         conv2d_1518[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1515 (Activation)    (None, None, None, 1 0           batch_normalization_1398[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1519 (Conv2D)            (None, None, None, 2 129024      activation_1515[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1399 (Batch (None, None, None, 2 672         conv2d_1519[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1516 (Activation)    (None, None, None, 2 0           batch_normalization_1399[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1517 (Conv2D)            (None, None, None, 1 399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1520 (Conv2D)            (None, None, None, 2 172032      activation_1516[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1397 (Batch (None, None, None, 1 576         conv2d_1517[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1400 (Batch (None, None, None, 2 768         conv2d_1520[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1514 (Activation)    (None, None, None, 1 0           batch_normalization_1397[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1517 (Activation)    (None, None, None, 2 0           batch_normalization_1400[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_mixed (Concatenate)    (None, None, None, 4 0           activation_1514[0][0]            \n",
      "                                                                 activation_1517[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_conv (Conv2D)          (None, None, None, 2 933920      block8_4_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4 (Lambda)               (None, None, None, 2 0           block8_3_ac[0][0]                \n",
      "                                                                 block8_4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_ac (Activation)        (None, None, None, 2 0           block8_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1522 (Conv2D)            (None, None, None, 1 399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1402 (Batch (None, None, None, 1 576         conv2d_1522[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1519 (Activation)    (None, None, None, 1 0           batch_normalization_1402[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1523 (Conv2D)            (None, None, None, 2 129024      activation_1519[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1403 (Batch (None, None, None, 2 672         conv2d_1523[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1520 (Activation)    (None, None, None, 2 0           batch_normalization_1403[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1521 (Conv2D)            (None, None, None, 1 399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1524 (Conv2D)            (None, None, None, 2 172032      activation_1520[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1401 (Batch (None, None, None, 1 576         conv2d_1521[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1404 (Batch (None, None, None, 2 768         conv2d_1524[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1518 (Activation)    (None, None, None, 1 0           batch_normalization_1401[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1521 (Activation)    (None, None, None, 2 0           batch_normalization_1404[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_mixed (Concatenate)    (None, None, None, 4 0           activation_1518[0][0]            \n",
      "                                                                 activation_1521[0][0]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "block8_5_conv (Conv2D)          (None, None, None, 2 933920      block8_5_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5 (Lambda)               (None, None, None, 2 0           block8_4_ac[0][0]                \n",
      "                                                                 block8_5_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_ac (Activation)        (None, None, None, 2 0           block8_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1526 (Conv2D)            (None, None, None, 1 399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1406 (Batch (None, None, None, 1 576         conv2d_1526[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1523 (Activation)    (None, None, None, 1 0           batch_normalization_1406[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1527 (Conv2D)            (None, None, None, 2 129024      activation_1523[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1407 (Batch (None, None, None, 2 672         conv2d_1527[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1524 (Activation)    (None, None, None, 2 0           batch_normalization_1407[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1525 (Conv2D)            (None, None, None, 1 399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1528 (Conv2D)            (None, None, None, 2 172032      activation_1524[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1405 (Batch (None, None, None, 1 576         conv2d_1525[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1408 (Batch (None, None, None, 2 768         conv2d_1528[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1522 (Activation)    (None, None, None, 1 0           batch_normalization_1405[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1525 (Activation)    (None, None, None, 2 0           batch_normalization_1408[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_mixed (Concatenate)    (None, None, None, 4 0           activation_1522[0][0]            \n",
      "                                                                 activation_1525[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_conv (Conv2D)          (None, None, None, 2 933920      block8_6_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6 (Lambda)               (None, None, None, 2 0           block8_5_ac[0][0]                \n",
      "                                                                 block8_6_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_ac (Activation)        (None, None, None, 2 0           block8_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1530 (Conv2D)            (None, None, None, 1 399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1410 (Batch (None, None, None, 1 576         conv2d_1530[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1527 (Activation)    (None, None, None, 1 0           batch_normalization_1410[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1531 (Conv2D)            (None, None, None, 2 129024      activation_1527[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1411 (Batch (None, None, None, 2 672         conv2d_1531[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1528 (Activation)    (None, None, None, 2 0           batch_normalization_1411[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1529 (Conv2D)            (None, None, None, 1 399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1532 (Conv2D)            (None, None, None, 2 172032      activation_1528[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1409 (Batch (None, None, None, 1 576         conv2d_1529[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1412 (Batch (None, None, None, 2 768         conv2d_1532[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1526 (Activation)    (None, None, None, 1 0           batch_normalization_1409[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1529 (Activation)    (None, None, None, 2 0           batch_normalization_1412[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_mixed (Concatenate)    (None, None, None, 4 0           activation_1526[0][0]            \n",
      "                                                                 activation_1529[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_conv (Conv2D)          (None, None, None, 2 933920      block8_7_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7 (Lambda)               (None, None, None, 2 0           block8_6_ac[0][0]                \n",
      "                                                                 block8_7_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_ac (Activation)        (None, None, None, 2 0           block8_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1534 (Conv2D)            (None, None, None, 1 399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1414 (Batch (None, None, None, 1 576         conv2d_1534[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1531 (Activation)    (None, None, None, 1 0           batch_normalization_1414[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1535 (Conv2D)            (None, None, None, 2 129024      activation_1531[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1415 (Batch (None, None, None, 2 672         conv2d_1535[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1532 (Activation)    (None, None, None, 2 0           batch_normalization_1415[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1533 (Conv2D)            (None, None, None, 1 399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1536 (Conv2D)            (None, None, None, 2 172032      activation_1532[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1413 (Batch (None, None, None, 1 576         conv2d_1533[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1416 (Batch (None, None, None, 2 768         conv2d_1536[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1530 (Activation)    (None, None, None, 1 0           batch_normalization_1413[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1533 (Activation)    (None, None, None, 2 0           batch_normalization_1416[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_mixed (Concatenate)    (None, None, None, 4 0           activation_1530[0][0]            \n",
      "                                                                 activation_1533[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_conv (Conv2D)          (None, None, None, 2 933920      block8_8_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8 (Lambda)               (None, None, None, 2 0           block8_7_ac[0][0]                \n",
      "                                                                 block8_8_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_ac (Activation)        (None, None, None, 2 0           block8_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1538 (Conv2D)            (None, None, None, 1 399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1418 (Batch (None, None, None, 1 576         conv2d_1538[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1535 (Activation)    (None, None, None, 1 0           batch_normalization_1418[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1539 (Conv2D)            (None, None, None, 2 129024      activation_1535[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1419 (Batch (None, None, None, 2 672         conv2d_1539[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1536 (Activation)    (None, None, None, 2 0           batch_normalization_1419[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1537 (Conv2D)            (None, None, None, 1 399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1540 (Conv2D)            (None, None, None, 2 172032      activation_1536[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1417 (Batch (None, None, None, 1 576         conv2d_1537[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1420 (Batch (None, None, None, 2 768         conv2d_1540[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1534 (Activation)    (None, None, None, 1 0           batch_normalization_1417[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1537 (Activation)    (None, None, None, 2 0           batch_normalization_1420[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_mixed (Concatenate)    (None, None, None, 4 0           activation_1534[0][0]            \n",
      "                                                                 activation_1537[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_conv (Conv2D)          (None, None, None, 2 933920      block8_9_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9 (Lambda)               (None, None, None, 2 0           block8_8_ac[0][0]                \n",
      "                                                                 block8_9_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_ac (Activation)        (None, None, None, 2 0           block8_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1542 (Conv2D)            (None, None, None, 1 399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1422 (Batch (None, None, None, 1 576         conv2d_1542[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1539 (Activation)    (None, None, None, 1 0           batch_normalization_1422[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1543 (Conv2D)            (None, None, None, 2 129024      activation_1539[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1423 (Batch (None, None, None, 2 672         conv2d_1543[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1540 (Activation)    (None, None, None, 2 0           batch_normalization_1423[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1541 (Conv2D)            (None, None, None, 1 399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1544 (Conv2D)            (None, None, None, 2 172032      activation_1540[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1421 (Batch (None, None, None, 1 576         conv2d_1541[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1424 (Batch (None, None, None, 2 768         conv2d_1544[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1538 (Activation)    (None, None, None, 1 0           batch_normalization_1421[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1541 (Activation)    (None, None, None, 2 0           batch_normalization_1424[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_mixed (Concatenate)   (None, None, None, 4 0           activation_1538[0][0]            \n",
      "                                                                 activation_1541[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_conv (Conv2D)         (None, None, None, 2 933920      block8_10_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_10 (Lambda)              (None, None, None, 2 0           block8_9_ac[0][0]                \n",
      "                                                                 block8_10_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b (Conv2D)                (None, None, None, 1 3194880     block8_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_bn (BatchNormalization) (None, None, None, 1 4608        conv_7b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_ac (Activation)         (None, None, None, 1 0           conv_7b_bn[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 54,336,736\n",
      "Trainable params: 54,276,192\n",
      "Non-trainable params: 60,544\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'Dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-41e63e643a03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \"\"\"\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# pydot raises a generic Exception here,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# so no specific class can be caught.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[1;32m     28\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "print(base_model_1.summary())\n",
    "from keras.utils import plot_model\n",
    "plot_model(base_model_1, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
