{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use inceptionv4 and multiple input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/cv/miniconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "/home/cv/miniconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1203, 75, 75, 3) (1203, 1) (1203, 2)\n",
      "(401, 75, 75, 3) (401, 1) (401, 2)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plt_images(X_images):\n",
    "    plt.imshow(X_images,cmap = plt.cm.gray)\n",
    "\n",
    "def data_normal(X_,y_,is_training):\n",
    "    '''Create 3-channel 'images'. Return rescale-normalised images.'''\n",
    "    images = []\n",
    "    avergae_bright=[]\n",
    "    index=1\n",
    "    for i, row in X_.iterrows():\n",
    "        # Formulate the bands as 75x75 arrays\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        band_3 = (band_1+band_2)/2\n",
    "        \n",
    "        # Rescale\n",
    "        r = (band_1 - band_1.min()) / (band_1.max() - band_1.min())\n",
    "        g = (band_2 - band_2.min()) / (band_2.max() - band_2.min())\n",
    "        b = (band_3 - band_3.min()) / (band_3.max() - band_3.min())\n",
    "        rgb = np.dstack((r, g, b))\n",
    "        images.append(rgb)\n",
    "        \n",
    "    X_data_angle=np.reshape(np.sin(X_[\"inc_angle\"]),(X_[\"inc_angle\"].shape[0],1))\n",
    "    X_data_plus=np.concatenate([X_data_angle[:, np.newaxis]], \n",
    "                              axis=2)\n",
    "    X_data_plus=X_data_plus.reshape(X_data_plus.shape[0],X_data_plus.shape[2])\n",
    "    if is_training:\n",
    "        y_data = keras.utils.to_categorical(y_, num_classes)\n",
    "    else:\n",
    "        y_data = None\n",
    "\n",
    "    return (np.array(images),X_data_plus,y_data)\n",
    "\n",
    "# Define threadsafe_generator\n",
    "# If we want to use data augmentation in training process,we have to use @threadsafe_generator to make any generator thread safe.\n",
    "\n",
    "# Note: A non thread safe generator in a multithreaded envrionment just crashes, yieldsing a 'ValueError: generator already executing' error.You can try it yourself by removing the @threadsafe_generator decorator from count().\n",
    "\n",
    "# Also, since we have to use multiple generators to feed both the image data and the angle data, we have to define our own generator: generator_img_angle()\n",
    "\n",
    "import threading\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "class threadsafe_iter:\n",
    "    \"\"\"Takes an iterator/generator and makes it thread-safe by\n",
    "    serializing call to the `next` method of given iterator/generator.\n",
    "    \"\"\"\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "        self.lock = threading.Lock()\n",
    " \n",
    "    def __iter__(self):\n",
    "        return self\n",
    " \n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            return self.it.__next__()\n",
    " \n",
    "def threadsafe_generator(f):\n",
    "    \"\"\"A decorator that takes a generator function and makes it thread-safe.\n",
    "    \"\"\"\n",
    "    def g(*a, **kw):\n",
    "        return threadsafe_iter(f(*a, **kw))\n",
    "    return g\n",
    " \n",
    "    \n",
    "@threadsafe_generator\n",
    "def generator_img_plus_new( generator, X1, X2, y, batch_size = 32 ):\n",
    "    SEED=816\n",
    "    generator_seed = np.random.randint( SEED )\n",
    "    gen_X1 = generator.flow( X1, y, \n",
    "                             batch_size = batch_size, seed = generator_seed )\n",
    "    gen_X2 = generator.flow( X1, X2, \n",
    "                             batch_size = batch_size, seed = generator_seed )\n",
    "\n",
    "    while True:\n",
    "        X1i = gen_X1.next()\n",
    "        X2i = gen_X2.next()\n",
    "\n",
    "        yield [ X1i[0], X2i[1] ], X1i[1]\n",
    "        \n",
    "        \n",
    "#load data\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import json\n",
    "import keras\n",
    "import math\n",
    "#Load the data.\n",
    "train = pd.read_json(\"../input/train.json\")\n",
    "\n",
    "#use mean of angle to replace \"na\"\n",
    "inc_angle = train.inc_angle.replace('na',0)\n",
    "idx=np.where(inc_angle==0)\n",
    "inc_angle = inc_angle.drop(idx[0])\n",
    "inc_mean=np.mean(inc_angle)\n",
    "train.inc_angle = train.inc_angle.replace('na',inc_mean)\n",
    "# train=train.drop(idx[0])\n",
    "# train.inc_angle = train.inc_angle.replace('na',0)\n",
    "    \n",
    "                      \n",
    "#Do Data Cleaning on training data and validation data                   \n",
    "num_classes=2\n",
    "\n",
    "y_train=train['is_iceberg']\n",
    "\n",
    "X_train_cv, X_valid, y_train_cv, y_valid = train_test_split(train,y_train, random_state=1, train_size=0.75)\n",
    "\n",
    "X_train_cv,X_train_plus,y_train_cv=data_normal(X_train_cv,y_train_cv,is_training=True)\n",
    "X_valid,X_valid_plus,y_valid=data_normal(X_valid,y_valid,is_training=True)\n",
    "\n",
    "print(X_train_cv.shape,X_train_plus.shape,y_train_cv.shape)\n",
    "print(X_valid.shape,X_valid_plus.shape,y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train model\n",
    "\n",
    "If we use data augmentaion, use the model.fit_generator version, otherwise use model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "38/38 [==============================] - 78s 2s/step - loss: 74.0635 - acc: 0.6658 - val_loss: 30.2378 - val_acc: 0.5312\n",
      "Epoch 2/400\n",
      "38/38 [==============================] - 9s 248ms/step - loss: 16.3154 - acc: 0.8072 - val_loss: 7.8551 - val_acc: 0.7980\n",
      "Epoch 3/400\n",
      "38/38 [==============================] - 9s 247ms/step - loss: 4.7800 - acc: 0.8358 - val_loss: 2.7154 - val_acc: 0.8579\n",
      "Epoch 4/400\n",
      "38/38 [==============================] - 7s 193ms/step - loss: 1.8217 - acc: 0.8475 - val_loss: 1.1484 - val_acc: 0.8454\n",
      "Epoch 5/400\n",
      "38/38 [==============================] - 7s 193ms/step - loss: 0.8995 - acc: 0.8503 - val_loss: 0.7078 - val_acc: 0.8304\n",
      "Epoch 6/400\n",
      "38/38 [==============================] - 9s 248ms/step - loss: 0.5954 - acc: 0.8481 - val_loss: 0.5253 - val_acc: 0.8903\n",
      "Epoch 7/400\n",
      "38/38 [==============================] - 7s 193ms/step - loss: 0.4799 - acc: 0.8711 - val_loss: 0.4750 - val_acc: 0.8529\n",
      "Epoch 8/400\n",
      "38/38 [==============================] - 7s 192ms/step - loss: 0.4367 - acc: 0.8676 - val_loss: 0.4270 - val_acc: 0.8678\n",
      "Epoch 9/400\n",
      "38/38 [==============================] - 7s 193ms/step - loss: 0.4120 - acc: 0.8799 - val_loss: 0.4159 - val_acc: 0.8728\n",
      "Epoch 10/400\n",
      "38/38 [==============================] - 7s 193ms/step - loss: 0.4240 - acc: 0.8508 - val_loss: 0.6105 - val_acc: 0.7606\n",
      "Epoch 11/400\n",
      "38/38 [==============================] - 7s 193ms/step - loss: 0.4156 - acc: 0.8643 - val_loss: 0.3707 - val_acc: 0.8778\n",
      "Epoch 12/400\n",
      "38/38 [==============================] - 7s 193ms/step - loss: 0.4048 - acc: 0.8719 - val_loss: 0.4334 - val_acc: 0.8579\n",
      "Epoch 13/400\n",
      "38/38 [==============================] - 7s 193ms/step - loss: 0.4006 - acc: 0.8654 - val_loss: 0.4069 - val_acc: 0.8653\n",
      "Epoch 14/400\n",
      "38/38 [==============================] - 7s 193ms/step - loss: 0.4234 - acc: 0.8687 - val_loss: 0.4168 - val_acc: 0.8778\n",
      "Epoch 15/400\n",
      "38/38 [==============================] - 7s 194ms/step - loss: 0.4074 - acc: 0.8689 - val_loss: 0.3960 - val_acc: 0.8778\n",
      "Epoch 16/400\n",
      "38/38 [==============================] - 7s 193ms/step - loss: 0.3673 - acc: 0.8818 - val_loss: 0.4146 - val_acc: 0.8479\n",
      "Epoch 17/400\n",
      "14/38 [==========>...................] - ETA: 4s - loss: 0.3607 - acc: 0.8862"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4bb314e6387f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    156\u001b[0m                                                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                                                         \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                                                         mode='auto')])\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;31m# Save model and weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2145\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2146\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2147\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1837\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.densenet import DenseNet\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.models import load_model \n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D,Dense, Activation, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input\n",
    "\n",
    "import math\n",
    "import os\n",
    "import keras\n",
    "\n",
    "#Macro defined\n",
    "batch_size =32\n",
    "num_classes =2\n",
    "epochs = 400\n",
    "batch_num_per_epoch=math.ceil(X_train_cv.shape[0]/batch_size)\n",
    "batch_num_val=math.ceil(X_valid.shape[0]/batch_size)\n",
    "data_augmentation = True\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_iceberg_transe.h5'\n",
    "filepath=\"keras_iceberg_transe_epoch_mymodel.h5\"\n",
    "\n",
    "def conv2d_block(inputs,kernel_size,strides,filters):\n",
    "    x=Conv2D(filters=filters,kernel_size= kernel_size,strides=strides, padding='same',\n",
    "           input_shape=X_train_cv.shape[1:],kernel_initializer='glorot_normal',\n",
    "           use_bias=True,kernel_regularizer=keras.regularizers.l2(0.03))(inputs)\n",
    "    \n",
    "    x=BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, \n",
    "                                scale=True, beta_initializer='zeros', gamma_initializer='ones', \n",
    "                                moving_mean_initializer='zeros', moving_variance_initializer='ones')(x)\n",
    "#     x=advanced_activations.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=None)(x)\n",
    "    x=keras.layers.advanced_activations.LeakyReLU(alpha=0.3)(x)\n",
    "    return x\n",
    "\n",
    "def dense_block(inputs,filter_num):\n",
    "    x=Dense(filter_num,kernel_initializer='he_normal',kernel_regularizer=regularizers.l2(0.1))(inputs)\n",
    "    x=keras.layers.advanced_activations.LeakyReLU(alpha=0.01)(x)\n",
    "    x=Dropout(0.4)(x)\n",
    "    return x\n",
    "    \n",
    "# create the base pre-trained model\n",
    "\n",
    "#dense_net\n",
    "# base_model=DenseNet(blocks=[6, 12, 48, 32],\n",
    "#              include_top=False,\n",
    "#              weights='imagenet',\n",
    "#              input_tensor=None,\n",
    "#              input_shape=None,\n",
    "#              pooling=None,\n",
    "#              classes=1000)\n",
    "# x= base_model.output\n",
    "\n",
    "#inception_v4\n",
    "base_model=InceptionResNetV2(include_top=False,weights='imagenet', input_tensor=None, \n",
    "                             input_shape=None, pooling=None, classes=1000)\n",
    "x= base_model.output\n",
    "\n",
    "#inception_v3\n",
    "# base_model=keras.applications.inception_v3.InceptionV3(include_top=False,\n",
    "#                                             weights='imagenet',\n",
    "#                                             input_tensor=None,\n",
    "#                                             input_shape=None,\n",
    "#                                             pooling=None,\n",
    "#                                             classes=1000)\n",
    "# x= base_model.get_layer('mixed4').output\n",
    "\n",
    "#vgg16\n",
    "# base_model=keras.applications.vgg16.VGG16(include_top=False,weights='imagenet',\n",
    "#                                 input_tensor=None, input_shape=None,\n",
    "#                                 pooling=None,\n",
    "#                                 classes=1)\n",
    "# x= base_model.get_layer('block4_pool').output\n",
    "\n",
    "#vgg-19\n",
    "# base_model=keras.applications.vgg19.VGG19(include_top=False, weights='imagenet',\n",
    "#                                 input_tensor=None, input_shape=None,\n",
    "#                                 pooling=None,\n",
    "#                                 classes=1000)\n",
    "# x= base_model.get_layer('block5_pool').output\n",
    "\n",
    "#xception\n",
    "# base_model=keras.applications.xception.Xception(include_top=False, weights='imagenet',\n",
    "#                                     input_tensor=None, input_shape=None,\n",
    "#                                     pooling=None, classes=1000)\n",
    "# x= base_model.get_layer('block14_sepconv1_act').output\n",
    "\n",
    "#resnet-50\n",
    "# base_model=keras.applications.resnet50.ResNet50(include_top=False, weights='imagenet',\n",
    "#                                 input_tensor=None, input_shape=None,\n",
    "#                                 pooling=None,\n",
    "#                                 classes=1000)\n",
    "# x= base_model.get_layer('avg_pool').output\n",
    "\n",
    "\n",
    "image_out = GlobalAveragePooling2D()(x)\n",
    "plus_input = Input(shape=(1,), name='plus_input')\n",
    "x=image_out\n",
    "x = keras.layers.concatenate([image_out, plus_input],axis=-1)\n",
    "x=dense_block(x,512)\n",
    "x=dense_block(x,256)\n",
    "x=dense_block(x,128)\n",
    "\n",
    "predictions = Dense(num_classes, activation='sigmoid',name='main_output',kernel_initializer='he_normal',\n",
    "                   kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=[base_model.input, plus_input], outputs=predictions)\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "opt=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#input data\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "# model.fit([X_train_cv, X_train_plus],y_train_cv,\n",
    "#           validation_data=([X_valid,X_valid_plus],y_valid),\n",
    "#           epochs=epochs, batch_size=batch_size,\n",
    "#           callbacks=[keras.callbacks.ModelCheckpoint(filepath,\n",
    "#                                                         monitor='val_acc',\n",
    "#                                                         verbose=0,\n",
    "#                                                         save_best_only=True, \n",
    "#                                                         mode='auto')])\n",
    "\n",
    "image_augmentation = ImageDataGenerator( rotation_range = 20,\n",
    "                                         horizontal_flip = True,\n",
    "                                         vertical_flip = True,\n",
    "                                         width_shift_range = .3,\n",
    "                                         height_shift_range =.3,\n",
    "                                         zoom_range = .1 )\n",
    "\n",
    "train_generator = generator_img_plus_new( image_augmentation, X_train_cv, \n",
    "                                X_train_plus, y_train_cv, \n",
    "                                batch_size = batch_size)\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                                    epochs=epochs,\n",
    "                                    validation_data=([X_valid,X_valid_plus],y_valid),\n",
    "#                                     validation_data=generator_img_plus(X_valid,X_valid_plus,y_valid,\n",
    "#                                                                         batch_size,is_training=True),\n",
    "#                                     validation_steps=batch_num_val,\n",
    "                                    workers=4,\n",
    "                                    steps_per_epoch=batch_num_per_epoch,\n",
    "                                    # 该回调函数将在每个epoch后保存模型到filepath\n",
    "                                    callbacks=[keras.callbacks.ModelCheckpoint(filepath,\n",
    "                                                        monitor='val_acc',\n",
    "                                                        verbose=0,\n",
    "                                                        save_best_only=True, \n",
    "                                                        mode='auto')])\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate([X_valid, X_valid_plus],y_valid, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401/401 [==============================] - 2s 6ms/step\n",
      "validation accuracy: [0.30113445367301789, 0.92518703509447286]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "# Score trained model.\n",
    "scores = model.evaluate([X_valid, X_valid_plus],y_valid, verbose=1)\n",
    "# batch_size=32\n",
    "# batch_num_val=math.ceil(X_valid.shape[0]/batch_size)\n",
    "# scores = model.evaluate_generator(generator_img_plus(X_valid, X_valid_plus, y_valid,batch_size=batch_size),\n",
    "#                                   steps=batch_num_val)\n",
    "\n",
    "print(\"validation accuracy:\",scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3.Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model_path=\"../iceberg_code/keras_iceberg_transe_epoch_mymodel.h5\"\n",
    "model = load_model(model_path)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cv/miniconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch0 has finished!\n",
      "\n",
      "batch1 has finished!\n",
      "\n",
      "batch2 has finished!\n",
      "\n",
      "batch3 has finished!\n",
      "\n",
      "batch4 has finished!\n",
      "\n",
      "batch5 has finished!\n",
      "\n",
      "batch6 has finished!\n",
      "\n",
      "batch7 has finished!\n",
      "\n",
      "batch8 has finished!\n",
      "\n",
      "batch9 has finished!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "cut_set_num=10\n",
    "lenth_test=8424\n",
    "num_classes=2\n",
    "is_training=False\n",
    "test_path=\"../input/test_cut/\"\n",
    "batch_size=32\n",
    "\n",
    "\n",
    "predicted_test=[]\n",
    "result_max=[]\n",
    "test_id=[]\n",
    "\n",
    "\n",
    "for ci in range(cut_set_num):\n",
    "    test_pathi=test_path+\"test%d.json\"%ci\n",
    "    test_json_str = open(test_pathi, 'r').readlines()[0]\n",
    "    test=pd.read_json(test_json_str)\n",
    "    \n",
    "    #use mean of angle to replace \"na\"\n",
    "    inc_angle = test.inc_angle.replace('na',0)\n",
    "    idx=np.where(inc_angle==0)\n",
    "    inc_angle = inc_angle.drop(idx[0])\n",
    "    inc_mean=np.mean(inc_angle)\n",
    "    test.inc_angle = test.inc_angle.replace('na',inc_mean)\n",
    "#     test= test.drop(idx[0])\n",
    "#     test.inc_angle = test.inc_angle.replace('na',0)\n",
    "   \n",
    "    X_test,X_test_plus,y_test=data_normal(X_=test,y_=None,is_training=False)\n",
    "    batch_num_predic=math.ceil(X_test.shape[0]/batch_size)\n",
    "#     print(X_test.shape[0],batch_num_predic)\n",
    "    #发现一个问题,steps总是比我设置的多出10\n",
    "    predicted_testi=model.predict([X_test,X_test_plus])\n",
    "    \n",
    "#     predicted_testi=model.predict_generator(generator_img_angle(X11=X_test,\n",
    "#                                                                 X2=X_test_angle, \n",
    "#                                                                 Y=None,\n",
    "#                                                                 batch_size=batch_size,\n",
    "#                                                                 is_training=False),\n",
    "#                                             steps=batch_num_predic)\n",
    "    \n",
    "    test_id.extend(test[\"id\"])\n",
    "    predicted_testi=predicted_testi.reshape(predicted_testi.shape[0],2)\n",
    "    for index in range(len(predicted_testi)):\n",
    "        predicted_test.append(predicted_testi[index][1])\n",
    "    result_max.extend( np.argmax(predicted_testi, axis = 1) )\n",
    "    \n",
    "    print(\"batch%d has finished!\"%ci)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8424 8424 8424\n"
     ]
    }
   ],
   "source": [
    "# save result\n",
    "submission = pd.DataFrame()\n",
    "print(len(test_id),len(result_max),len(predicted_test))\n",
    "submission['id']=test_id\n",
    "submission['is_iceberg']=result_max\n",
    "submission.to_csv('sub.csv', index=False)\n",
    "# save probablity\n",
    "\n",
    "submission['is_iceberg']=predicted_test\n",
    "submission.to_csv('plus_inceptionv3.csv', index=False,float_format=\"%.6lf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'Dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8691c502d439>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# print(model.summary())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \"\"\"\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# pydot raises a generic Exception here,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# so no specific class can be caught.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[1;32m     28\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "# print(model.summary())\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
