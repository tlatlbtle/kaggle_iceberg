{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use my_net multi input version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data clean function\n",
    "if you need to do zero center, you should use data_normal rather than data_clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_normal(X_,y_,is_training):\n",
    "    '''Create 3-channel 'images'. Return rescale-normalised images.'''\n",
    "    images = []\n",
    "    for i, row in X_.iterrows():\n",
    "        # Formulate the bands as 75x75 arrays\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        band_3 = (band_1+band_2)/2\n",
    "\n",
    "        # Rescale\n",
    "        r = (band_1 - band_1.min()) / (band_1.max() - band_1.min())\n",
    "        g = (band_2 - band_2.min()) / (band_2.max() - band_2.min())\n",
    "        b = (band_3 - band_3.min()) / (band_3.max() - band_3.min())\n",
    "\n",
    "        rgb = np.dstack((r, g, b))\n",
    "        images.append(rgb)\n",
    "        \n",
    "    X_data_angle=np.reshape(X_[\"inc_angle\"],(X_[\"inc_angle\"].shape[0],1))\n",
    "    if is_training:\n",
    "        y_data = keras.utils.to_categorical(y_, num_classes)\n",
    "        \n",
    "    else:\n",
    "        y_data = None\n",
    "    return (np.array(images),X_data_angle,y_data)\n",
    "\n",
    "def data_clean(X_,y_,is_training):\n",
    "    \n",
    "    X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in X_[\"band_1\"]])\n",
    "    X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in X_[\"band_2\"]])\n",
    "\n",
    "    X_data = np.concatenate([X_band_1[:, :, :, np.newaxis], \n",
    "                              X_band_2[:, :, :, np.newaxis], \n",
    "                              ((X_band_1+X_band_2)/2)[:, :, :, np.newaxis]], \n",
    "                             axis=-1)\n",
    "    X_data_angle=np.reshape(X_[\"inc_angle\"],(X_[\"inc_angle\"].shape[0],1))\n",
    "    if is_training:\n",
    "        y_data = keras.utils.to_categorical(y_, num_classes)\n",
    "    else:\n",
    "        y_data = None\n",
    "    return (X_data,X_data_angle,y_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define threadsafe_generator \n",
    "If we want to use data augmentation in training process,we have to use @threadsafe_generator to make any generator thread safe.\n",
    "\n",
    "Note: A non thread safe generator in a multithreaded envrionment just crashes, yieldsing a  'ValueError: generator already executing' error.You can try it yourself by removing the @threadsafe_generator decorator from count().\n",
    "\n",
    "Also, since we have to use multiple generators to feed both the image data and the angle data, we have to define our own generator: generator_img_angle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do Data Cleaning on training data and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cv/miniconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1203, 75, 75, 3) (1203, 1) (1203, 2)\n",
      "(401, 75, 75, 3) (401, 1) (401, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cv/miniconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import json\n",
    "import keras\n",
    "import math\n",
    "#Load the data.\n",
    "train = pd.read_json(\"../input/train.json\")\n",
    "\n",
    "#use mean of angle to replace \"na\"\n",
    "inc_angle = train.inc_angle.replace('na',0)\n",
    "idx=np.where(inc_angle==0)\n",
    "inc_angle = inc_angle.drop(idx[0])\n",
    "inc_mean=np.mean(inc_angle)\n",
    "train.inc_angle = train.inc_angle.replace('na',inc_mean)\n",
    "# train.inc_angle = train.inc_angle.replace('na',0)\n",
    "num_classes=2\n",
    "\n",
    "\n",
    "y_train=train['is_iceberg']\n",
    "\n",
    "X_train_cv, X_valid, y_train_cv, y_valid = train_test_split(train,y_train, random_state=1, train_size=0.75)\n",
    "X_train_cv,X_train_angle,y_train_cv=data_clean(X_train_cv,y_train_cv,is_training=True)\n",
    "X_valid,X_valid_angle,y_valid=data_clean(X_valid,y_valid,is_training=True)\n",
    "\n",
    "# X_train_cv,X_train_angle,y_train_cv=data_normal(X_train_cv,y_train_cv,is_training=True)\n",
    "# X_valid,X_valid_angle,y_valid=data_normal(X_valid,y_valid,is_training=True)\n",
    "\n",
    "print(X_train_cv.shape,X_train_angle.shape,y_train_cv.shape)\n",
    "print(X_valid.shape,X_valid_angle.shape,y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just for fun, post a tweet when the val_acc has been updated\n",
    "\n",
    "If you want to use this function, you have to add my_call_back in \"callbacks\" list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "class threadsafe_iter:\n",
    "    \"\"\"Takes an iterator/generator and makes it thread-safe by\n",
    "    serializing call to the `next` method of given iterator/generator.\n",
    "    \"\"\"\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "        self.lock = threading.Lock()\n",
    " \n",
    "    def __iter__(self):\n",
    "        return self\n",
    " \n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            return self.it.__next__()\n",
    " \n",
    "def threadsafe_generator(f):\n",
    "    \"\"\"A decorator that takes a generator function and makes it thread-safe.\n",
    "    \"\"\"\n",
    "    def g(*a, **kw):\n",
    "        return threadsafe_iter(f(*a, **kw))\n",
    "    return g\n",
    " \n",
    "\n",
    "def plt_images(X_images):\n",
    "    fig = plt.figure(200, figsize=(15, 15))\n",
    "    random_indicies = np.random.choice(range(len(X_images)), 9, False)\n",
    "    subset = X_images[random_indicies]\n",
    "    for i in range(9):\n",
    "        ax = fig.add_subplot(3, 3, i + 1)\n",
    "        ax.imshow(subset[i])\n",
    "    plt.show()\n",
    "    \n",
    "@threadsafe_generator\n",
    "def generator_img_angle(X1, X2, Y,batch_size=32,is_training=True):\n",
    "#     index=1\n",
    "    while True:\n",
    "        if is_training:\n",
    "            idx = np.random.permutation( X1.shape[0])\n",
    "        else:\n",
    "            idx =range(X1.shape[0])\n",
    "        datagen = ImageDataGenerator(featurewise_center=True,  # set input mean to 0 over the dataset\n",
    "                                     samplewise_center=False,  # set each sample mean to 0\n",
    "                                     featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "                                     samplewise_std_normalization=False,  # divide each input by its std\n",
    "                                     zca_whitening=False,  # apply ZCA whitening\n",
    "                                     rotation_range=False,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                                     width_shift_range=False,  # randomly shift images horizontally (fraction of total width)\n",
    "                                     height_shift_range=False,  # randomly shift images vertically (fraction of total height)\n",
    "                                     horizontal_flip=False,  # randomly flip images\n",
    "                                     vertical_flip=False)  # randomly flip image\n",
    "        datagen.fit(X1)\n",
    "        if is_training:\n",
    "            batches = datagen.flow(X1,Y,batch_size=batch_size,shuffle=False)\n",
    "        else:\n",
    "            batches = datagen.flow(X1,batch_size=batch_size,shuffle=False)\n",
    "        idx0 = 0\n",
    "#         print(\"batch num:\",len(batches))\n",
    "        for batch in batches:\n",
    "#             print(\"\\nidx:%d\\n\"%index)\n",
    "#             print(\"batch numi:\",len(batch))\n",
    "#             index+=1\n",
    "            if is_training:\n",
    "                idx1 = idx0 + batch[0].shape[0]\n",
    "            else:\n",
    "                idx1=idx0 + batch.shape[0]\n",
    "            # plot images\n",
    "#             X_images=batch[0]\n",
    "#             plt_images(X_images)\n",
    "            if is_training:\n",
    "                yield [batch[0], X2[ idx[ idx0:idx1 ] ]], batch[1]\n",
    "            else:\n",
    "                yield [batch, X2[ idx[ idx0:idx1 ] ]]\n",
    "            idx0 = idx1\n",
    "            if idx1 >= X1.shape[0]:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib import parse,request\n",
    "headers = {\n",
    "\"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n",
    "\"Accept-Encoding\":\"gzip, deflate, br\",\n",
    "\"Accept-Language\":\"zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "\"Cache-Control\":\"max-age=0\",\n",
    "\"Connection\":\"keep-alive\",\n",
    "\"Content-Type\":\"application/x-www-form-urlencoded\",\n",
    "\"Cookie\":\"_T_WM=977f85fa803c66b53d32bc3154488755; ALF=1517195081; SCF=Ar3eydUgzdi_dflitqApnqkIrqkmy2KVgbt_DLDlyqKCaF-qLn8iFGjp1fFELeOstkWfTkyH-OPVA3trocoCkLA.; SUB=_2A253Q1QnDeRhGeBO71oR9i3Fwj-IHXVUzHxvrDV6PUJbktANLVDfkW1NRew5lIyze7lEjwMqZII2Q3uZToA6X0BI; SUBP=0033WrSXqPxfM725Ws9jqgMF55529P9D9W5lYHIxViFXVlcOoSRecgrN5JpX5K-hUgL.Foq7Shn7Soe41Ke2dJLoI7v.qg4oIg4rKsLu9-pDdJjt; SUHB=0P1MbOkE2VISXc; SSOLoginState=1514611831\",\n",
    "\"Host\":\"weibo.cn\",\n",
    "\"Origin\":\"https://weibo.cn\",\n",
    "\"Referer\":\"https://weibo.cn/\",\n",
    "\"Upgrade-Insecure-Requests\":\"1\",\n",
    "\"User-Agent\":\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/63.0.3239.84 Chrome/63.0.3239.84 Safari/537.36\"\n",
    "}\n",
    "\n",
    "url=\"https://weibo.cn/mblog/sendmblog?st=431d54\"\n",
    "# if val_acc update, it will update a weibo \n",
    "class My_call_back(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.best_val_acc=0.87\n",
    "\n",
    "    def on_epoch_end(self, epoch,logs={}):\n",
    "        now_val_acc=logs.get('val_acc')\n",
    "        if now_val_acc>self.best_val_acc:\n",
    "            self.best_val_acc=now_val_acc\n",
    "            #post a tweet\n",
    "            content=\"epoch %d has ended,best_val_acc has updated, now it is : %.10lf\\n\"%(epoch+1,self.best_val_acc)\n",
    "            print()\n",
    "            print(content)\n",
    "            post_data ={\n",
    "                \"rl\":\"0\",\n",
    "                \"content\":content\n",
    "            }\n",
    "            post_data = parse.urlencode(post_data).encode('utf-8')\n",
    "            req = request.Request(url=url,data=post_data,headers=headers)\n",
    "            res = request.urlopen(req).read()\n",
    "\n",
    "my_call_back = My_call_back()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train model\n",
    "\n",
    "If we use data augmentaion, use the model.fit_generator version, otherwise use model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 75, 75, 3)\n",
      "Train on 1203 samples, validate on 401 samples\n",
      "Epoch 1/80\n",
      "1203/1203 [==============================] - 6s 5ms/step - loss: 20.1225 - acc: 0.5428 - val_loss: 15.0000 - val_acc: 0.5312\n",
      "Epoch 2/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 11.5392 - acc: 0.5278 - val_loss: 8.4563 - val_acc: 0.5312\n",
      "Epoch 3/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 6.7668 - acc: 0.5387 - val_loss: 5.3498 - val_acc: 0.5312\n",
      "Epoch 4/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 4.4067 - acc: 0.5993 - val_loss: 3.7574 - val_acc: 0.6983\n",
      "Epoch 5/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 3.1330 - acc: 0.7531 - val_loss: 2.8815 - val_acc: 0.5810\n",
      "Epoch 6/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 2.4074 - acc: 0.7805 - val_loss: 2.3218 - val_acc: 0.7431\n",
      "Epoch 7/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 1.9655 - acc: 0.7972 - val_loss: 1.9925 - val_acc: 0.5536\n",
      "Epoch 8/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 1.5899 - acc: 0.8263 - val_loss: 1.7014 - val_acc: 0.6284\n",
      "Epoch 9/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 1.4655 - acc: 0.7963 - val_loss: 1.5569 - val_acc: 0.5436\n",
      "Epoch 10/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 1.4454 - acc: 0.7805 - val_loss: 1.4387 - val_acc: 0.5411\n",
      "Epoch 11/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 1.1644 - acc: 0.8121 - val_loss: 1.1817 - val_acc: 0.7456\n",
      "Epoch 12/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.9954 - acc: 0.8263 - val_loss: 1.0837 - val_acc: 0.7830\n",
      "Epoch 13/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 1.0174 - acc: 0.7872 - val_loss: 1.9670 - val_acc: 0.5312\n",
      "Epoch 14/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.9315 - acc: 0.8055 - val_loss: 0.9230 - val_acc: 0.8429\n",
      "Epoch 15/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.8876 - acc: 0.8188 - val_loss: 0.8932 - val_acc: 0.8579\n",
      "Epoch 16/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.7508 - acc: 0.8495 - val_loss: 0.9140 - val_acc: 0.7731\n",
      "Epoch 17/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.7748 - acc: 0.8238 - val_loss: 0.8580 - val_acc: 0.7930\n",
      "Epoch 18/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.7572 - acc: 0.8354 - val_loss: 1.6632 - val_acc: 0.5037\n",
      "Epoch 19/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.9706 - acc: 0.7672 - val_loss: 1.8644 - val_acc: 0.5312\n",
      "Epoch 20/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.8743 - acc: 0.8354 - val_loss: 1.2722 - val_acc: 0.5686\n",
      "Epoch 21/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.7638 - acc: 0.8421 - val_loss: 0.9774 - val_acc: 0.6135\n",
      "Epoch 22/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.6782 - acc: 0.8595 - val_loss: 0.7980 - val_acc: 0.8429\n",
      "Epoch 23/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.7336 - acc: 0.8279 - val_loss: 0.8741 - val_acc: 0.7556\n",
      "Epoch 24/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.6366 - acc: 0.8662 - val_loss: 0.6871 - val_acc: 0.8504\n",
      "Epoch 25/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.6933 - acc: 0.8113 - val_loss: 1.0339 - val_acc: 0.5810\n",
      "Epoch 26/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.6478 - acc: 0.8595 - val_loss: 1.1590 - val_acc: 0.6259\n",
      "Epoch 27/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.6770 - acc: 0.8354 - val_loss: 1.1550 - val_acc: 0.6209\n",
      "Epoch 28/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.7222 - acc: 0.8271 - val_loss: 0.6796 - val_acc: 0.8429\n",
      "Epoch 29/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.6389 - acc: 0.8537 - val_loss: 0.6274 - val_acc: 0.8554\n",
      "Epoch 30/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.6109 - acc: 0.8545 - val_loss: 0.8164 - val_acc: 0.6559\n",
      "Epoch 31/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.6157 - acc: 0.8662 - val_loss: 0.7626 - val_acc: 0.7556\n",
      "Epoch 32/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.6384 - acc: 0.8446 - val_loss: 0.6710 - val_acc: 0.8404\n",
      "Epoch 33/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.6397 - acc: 0.8396 - val_loss: 0.8245 - val_acc: 0.7282\n",
      "Epoch 34/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.6867 - acc: 0.8271 - val_loss: 0.7726 - val_acc: 0.7057\n",
      "Epoch 35/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.6386 - acc: 0.8479 - val_loss: 0.8181 - val_acc: 0.6683\n",
      "Epoch 36/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.6480 - acc: 0.8587 - val_loss: 1.3454 - val_acc: 0.5337\n",
      "Epoch 37/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.6330 - acc: 0.8495 - val_loss: 0.9363 - val_acc: 0.6584\n",
      "Epoch 38/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.6116 - acc: 0.8421 - val_loss: 0.7907 - val_acc: 0.6933\n",
      "Epoch 39/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.6113 - acc: 0.8662 - val_loss: 0.6024 - val_acc: 0.8603\n",
      "Epoch 40/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.6742 - acc: 0.8188 - val_loss: 0.8570 - val_acc: 0.7357\n",
      "Epoch 41/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.6138 - acc: 0.8537 - val_loss: 0.7035 - val_acc: 0.8030\n",
      "Epoch 42/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.5904 - acc: 0.8687 - val_loss: 0.7867 - val_acc: 0.6783\n",
      "Epoch 43/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.5894 - acc: 0.8537 - val_loss: 0.6457 - val_acc: 0.8304\n",
      "Epoch 44/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.6211 - acc: 0.8429 - val_loss: 0.5947 - val_acc: 0.8653\n",
      "Epoch 45/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.5752 - acc: 0.8662 - val_loss: 0.6160 - val_acc: 0.8379\n",
      "Epoch 46/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.6423 - acc: 0.8346 - val_loss: 0.7458 - val_acc: 0.7805\n",
      "Epoch 47/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.6485 - acc: 0.8462 - val_loss: 0.8208 - val_acc: 0.7057\n",
      "Epoch 48/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.5771 - acc: 0.8653 - val_loss: 0.7694 - val_acc: 0.7382\n",
      "Epoch 49/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.6028 - acc: 0.8470 - val_loss: 0.8344 - val_acc: 0.7332\n",
      "Epoch 50/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.5866 - acc: 0.8612 - val_loss: 0.8417 - val_acc: 0.6633\n",
      "Epoch 51/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.5966 - acc: 0.8603 - val_loss: 0.6697 - val_acc: 0.8180\n",
      "Epoch 52/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.6243 - acc: 0.8520 - val_loss: 2.3678 - val_acc: 0.5262\n",
      "Epoch 53/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.7114 - acc: 0.8171 - val_loss: 0.9989 - val_acc: 0.6534\n",
      "Epoch 54/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.5852 - acc: 0.8695 - val_loss: 0.5933 - val_acc: 0.8778\n",
      "Epoch 55/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.5799 - acc: 0.8637 - val_loss: 0.7902 - val_acc: 0.7307\n",
      "Epoch 56/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.5813 - acc: 0.8570 - val_loss: 0.6851 - val_acc: 0.7855\n",
      "Epoch 57/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.5953 - acc: 0.8637 - val_loss: 0.6922 - val_acc: 0.8130\n",
      "Epoch 58/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.5921 - acc: 0.8745 - val_loss: 0.5928 - val_acc: 0.8728\n",
      "Epoch 59/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.5475 - acc: 0.8878 - val_loss: 0.7460 - val_acc: 0.7456\n",
      "Epoch 60/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.6148 - acc: 0.8495 - val_loss: 0.6218 - val_acc: 0.8180\n",
      "Epoch 61/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.5648 - acc: 0.8645 - val_loss: 0.5674 - val_acc: 0.8678\n",
      "Epoch 62/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.5368 - acc: 0.8595 - val_loss: 0.6331 - val_acc: 0.8479\n",
      "Epoch 63/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.6144 - acc: 0.8545 - val_loss: 0.6784 - val_acc: 0.7781\n",
      "Epoch 64/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.6379 - acc: 0.8346 - val_loss: 0.6982 - val_acc: 0.7880\n",
      "Epoch 65/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.5984 - acc: 0.8620 - val_loss: 1.4435 - val_acc: 0.5885\n",
      "Epoch 66/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.6059 - acc: 0.8562 - val_loss: 0.7046 - val_acc: 0.7855\n",
      "Epoch 67/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.5725 - acc: 0.8745 - val_loss: 0.7522 - val_acc: 0.7032\n",
      "Epoch 68/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.5897 - acc: 0.8637 - val_loss: 0.7825 - val_acc: 0.7107\n",
      "Epoch 69/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.5862 - acc: 0.8595 - val_loss: 0.6568 - val_acc: 0.8055\n",
      "Epoch 70/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.5635 - acc: 0.8712 - val_loss: 0.7416 - val_acc: 0.7481\n",
      "Epoch 71/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.5759 - acc: 0.8645 - val_loss: 0.5769 - val_acc: 0.8753\n",
      "Epoch 72/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.5405 - acc: 0.8803 - val_loss: 0.6627 - val_acc: 0.8055\n",
      "Epoch 73/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.5874 - acc: 0.8712 - val_loss: 0.7255 - val_acc: 0.7731\n",
      "Epoch 74/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.5495 - acc: 0.8786 - val_loss: 0.5746 - val_acc: 0.8579\n",
      "Epoch 75/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.5713 - acc: 0.8687 - val_loss: 0.6902 - val_acc: 0.7855\n",
      "Epoch 76/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.5547 - acc: 0.8653 - val_loss: 0.5692 - val_acc: 0.8828\n",
      "Epoch 77/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.5608 - acc: 0.8761 - val_loss: 0.6216 - val_acc: 0.8404\n",
      "Epoch 78/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.6038 - acc: 0.8545 - val_loss: 0.6275 - val_acc: 0.8304\n",
      "Epoch 79/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.5403 - acc: 0.8853 - val_loss: 0.7205 - val_acc: 0.7681\n",
      "Epoch 80/80\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 0.5206 - acc: 0.8886 - val_loss: 0.6297 - val_acc: 0.8105\n",
      "Saved trained model at /home/cv/wjb/Iceberg Classifier Challenge/iceberg_code/saved_models/keras_iceberg_myownmodel2.h5 \n",
      "401/401 [==============================] - 0s 1ms/step\n",
      "Test loss: 0.629694443391\n",
      "Test accuracy: 0.810473816353\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import GlobalMaxPooling2D\n",
    "import os\n",
    "from keras import regularizers\n",
    "import math\n",
    "from keras.layers import advanced_activations\n",
    "\n",
    "#Macro defined\n",
    "batch_size =64\n",
    "num_classes =2\n",
    "epochs = 80\n",
    "batch_num_per_epoch=math.ceil(X_train_cv.shape[0]/batch_size)\n",
    "batch_num_val=math.ceil(X_valid.shape[0]/batch_size)\n",
    "data_augmentation = True\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_iceberg_myownmodel2.h5'\n",
    "filepath=\"keras_iceberg_epoch_mymodel.h5\"\n",
    "\n",
    "# create the base model\n",
    "def conv2d_block(inputs,kernel_size,filters):\n",
    "    x=Conv2D(filters=filters,kernel_size= kernel_size,strides=(1, 1), padding='same',\n",
    "           input_shape=X_train_cv.shape[1:],kernel_initializer='glorot_normal',\n",
    "           use_bias=True,kernel_regularizer=regularizers.l2(0.03))(inputs)\n",
    "    \n",
    "    x=BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, \n",
    "                                scale=True, beta_initializer='zeros', gamma_initializer='ones', \n",
    "                                moving_mean_initializer='zeros', moving_variance_initializer='ones')(x)\n",
    "#     x=advanced_activations.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=None)(x)\n",
    "    x=keras.layers.advanced_activations.LeakyReLU(alpha=0.3)(x)\n",
    "    x=MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x=Dropout(0.2)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def dense_block(x,filters):\n",
    "    x=Dense(filters,kernel_initializer='glorot_normal',kernel_regularizer=regularizers.l2(0.03))(x)\n",
    "    x=keras.layers.advanced_activations.LeakyReLU(alpha=0.3)(x)\n",
    "    x=Dropout(0.2)(x)\n",
    "    \n",
    "    return x\n",
    "# This returns a tensor\n",
    "main_input = Input(shape=X_train_cv.shape[1:],name='image_input')\n",
    "x=main_input\n",
    "# x=keras.layers.convolutional.Cropping2D(cropping=((10, 10), (10, 10)), data_format=None)(x)\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "# x = conv2d33_maxpool_block(main_input,(3,3),64)\n",
    "x = conv2d_block(x,(3,3),128)\n",
    "x = conv2d_block(x,(3,3),256)\n",
    "x = conv2d_block(x,(3,3),512)\n",
    "\n",
    "# You must flatten the data for the dense layers\n",
    "# x=Flatten()(x)\n",
    "# x=Dense(512)(x)\n",
    "# x = conv2d33_maxpool_block(x,(1,1),256)\n",
    "\n",
    "image_out=GlobalMaxPooling2D()(x)\n",
    "x=keras.layers.advanced_activations.LeakyReLU(alpha=0.3)(x)\n",
    "# x=advanced_activations.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=None)(x)\n",
    "x=Dropout(0.2)(x)\n",
    "\n",
    "#add time\n",
    "angle_input = Input(shape=(1,), name='angle_input')\n",
    "x = keras.layers.concatenate([image_out, angle_input],axis=-1)\n",
    "x=dense_block(x,256)\n",
    "x=dense_block(x,64)\n",
    "x=dense_block(x,16)\n",
    "\n",
    "# x=advanced_activations.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=None)(x)\n",
    "predictions = Dense(num_classes, activation='sigmoid',name='main_output',kernel_initializer='glorot_normal',\n",
    "                   kernel_regularizer=regularizers.l2(0.03))(x)\n",
    "\n",
    "# This creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "model = Model(inputs=[main_input, angle_input], outputs=predictions)\n",
    "\n",
    "opt=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#input data\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "model.fit({'image_input': X_train_cv, 'angle_input':  X_train_angle},\n",
    "          {'main_output': y_train_cv},\n",
    "          validation_data=([X_valid,X_valid_angle],y_valid),\n",
    "          epochs=epochs, batch_size=batch_size,\n",
    "          callbacks=[keras.callbacks.ModelCheckpoint(filepath,\n",
    "                                                        monitor='val_acc',\n",
    "                                                        verbose=0,\n",
    "                                                        save_best_only=True, \n",
    "                                                        mode='auto')])\n",
    "\n",
    "# model.fit_generator(generator_img_angle(X_train_cv, X_train_angle, y_train_cv,batch_size,is_training=True),\n",
    "#                                     epochs=epochs,\n",
    "# #                                     validation_data=([X_valid,X_valid_angle],y_valid),\n",
    "#                                     validation_data=generator_img_angle(X_valid,X_valid_angle,y_valid,\n",
    "#                                                                         batch_size,is_training=True),\n",
    "#                                     validation_steps=batch_num_val,\n",
    "#                                     workers=4,\n",
    "#                                     steps_per_epoch=batch_num_per_epoch,\n",
    "#                                     # 该回调函数将在每个epoch后保存模型到filepath\n",
    "#                                     callbacks=[keras.callbacks.ModelCheckpoint(filepath,\n",
    "#                                                         monitor='val_acc',\n",
    "#                                                         verbose=0,\n",
    "#                                                         save_best_only=True, \n",
    "#                                                         mode='auto')])\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate([X_valid, X_valid_angle],y_valid, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401/401 [==============================] - 1s 2ms/step\n",
      "validation accuracy: [0.56922518835400704, 0.88279301819955913]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "# Score trained model.\n",
    "scores = model.evaluate([X_valid, X_valid_angle],y_valid, verbose=1)\n",
    "# scores = model.evaluate_generator(generator_img_angle(X_valid, X_valid_angle, y_valid,batch_size=batch_size),\n",
    "#                                   steps=batch_num_val)\n",
    "\n",
    "print(\"validation accuracy:\",scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3.Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model_path=\"../iceberg_code/keras_iceberg_epoch_mymodel.h5\"\n",
    "model = load_model(model_path)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cv/miniconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch0 has finished!\n",
      "\n",
      "batch1 has finished!\n",
      "\n",
      "batch2 has finished!\n",
      "\n",
      "batch3 has finished!\n",
      "\n",
      "batch4 has finished!\n",
      "\n",
      "batch5 has finished!\n",
      "\n",
      "batch6 has finished!\n",
      "\n",
      "batch7 has finished!\n",
      "\n",
      "batch8 has finished!\n",
      "\n",
      "batch9 has finished!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "cut_set_num=10\n",
    "lenth_test=8424\n",
    "num_classes=2\n",
    "is_training=False\n",
    "test_path=\"../input/test_cut/\"\n",
    "batch_size=32\n",
    "\n",
    "\n",
    "predicted_test=[]\n",
    "result_max=[]\n",
    "test_id=[]\n",
    "\n",
    "\n",
    "for ci in range(cut_set_num):\n",
    "    test_pathi=test_path+\"test%d.json\"%ci\n",
    "    test_json_str = open(test_pathi, 'r').readlines()[0]\n",
    "    test=pd.read_json(test_json_str)\n",
    "    \n",
    "    #use mean of angle to replace \"na\"\n",
    "    inc_angle = test.inc_angle.replace('na',0)\n",
    "    idx=np.where(inc_angle==0)\n",
    "    inc_angle = inc_angle.drop(idx[0])\n",
    "    inc_mean=np.mean(inc_angle)\n",
    "    test.inc_angle = test.inc_angle.replace('na',inc_mean)\n",
    "#     test.inc_angle = test.inc_angle.replace('na',0)\n",
    "   \n",
    "    X_test,X_test_angle,y_test=data_normal(X_=test,y_=None,is_training=False)\n",
    "    batch_num_predic=math.ceil(X_test.shape[0]/batch_size)\n",
    "#     print(X_test.shape[0],batch_num_predic)\n",
    "    #发现一个问题,steps总是比我设置的多出10\n",
    "    predicted_testi=model.predict(X_test)\n",
    "    \n",
    "#     predicted_testi=model.predict_generator(generator_img_angle(X1=X_test,\n",
    "#                                                                 X2=X_test_angle, \n",
    "#                                                                 Y=None,\n",
    "#                                                                 batch_size=batch_size,\n",
    "#                                                                 is_training=False),\n",
    "#                                             steps=batch_num_predic)\n",
    "    \n",
    "    test_id.extend(test[\"id\"])\n",
    "    predicted_testi=predicted_testi.reshape(predicted_testi.shape[0],2)\n",
    "    for index in range(len(predicted_testi)):\n",
    "        predicted_test.append(predicted_testi[index][1])\n",
    "    result_max.extend( np.argmax(predicted_testi, axis = 1) )\n",
    "    \n",
    "    print(\"batch%d has finished!\"%ci)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8424 8424 8424\n"
     ]
    }
   ],
   "source": [
    "# save result\n",
    "submission = pd.DataFrame()\n",
    "print(len(test_id),len(result_max),len(predicted_test))\n",
    "submission['id']=test_id\n",
    "submission['is_iceberg']=result_max\n",
    "submission.to_csv('sub.csv', index=False)\n",
    "# save probablity\n",
    "submission['is_iceberg']=predicted_test\n",
    "submission.to_csv('simple_model.csv', index=False,float_format=\"%.8lf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image_input (InputLayer)        (None, 75, 75, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 75, 75, 128)  3584        image_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 75, 75, 128)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, 75, 75, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 37, 37, 128)  0           leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 37, 37, 128)  0           max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 37, 37, 256)  295168      dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 37, 37, 256)  1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)      (None, 37, 37, 256)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 18, 18, 256)  0           leaky_re_lu_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 18, 18, 256)  0           max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 18, 18, 512)  1180160     dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 18, 18, 512)  2048        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)      (None, 18, 18, 512)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 9, 9, 512)    0           leaky_re_lu_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 9, 9, 512)    0           max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_5 (GlobalM (None, 512)          0           dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "angle_input (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 513)          0           global_max_pooling2d_5[0][0]     \n",
      "                                                                 angle_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 256)          131584      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)      (None, 256)          0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 256)          0           leaky_re_lu_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 64)           16448       dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, 64)           0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 64)           0           leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 16)           1040        dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (None, 16)           0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 2)            34          leaky_re_lu_34[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 1,631,602\n",
      "Trainable params: 1,629,810\n",
      "Non-trainable params: 1,792\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'Dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a70009143d02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \"\"\"\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# pydot raises a generic Exception here,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# so no specific class can be caught.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[1;32m     28\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
